{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IQ-a3cM1EBhC"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "############################\n",
        "'''\n",
        "Template for the 4th assignment\n",
        "Student: Fabian Gobet\n",
        "'''\n",
        "import os\n",
        "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from accelerate import Accelerator\n",
        "import random\n",
        "import re\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "import statistics\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import itertools\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bPVvoUpsEBhD"
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "############################\n",
        "# Vocabulary class\n",
        "class Vocabulary:\n",
        "    '''\n",
        "    Class for dealing with our corpus\n",
        "    '''\n",
        "\n",
        "    def __init__(self, name, sentences):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            name (str): name of the language\n",
        "            pairs (list): list of pairs of sentences\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}\n",
        "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
        "        for s in sentences:\n",
        "            self.add_sentence(s)\n",
        "\n",
        "\n",
        "    def add_word(self, word):\n",
        "        '''\n",
        "        Add a word to the vocabulary\n",
        "        :param word: a string\n",
        "        '''\n",
        "        # TODO: add the word to the vocabulary\n",
        "        if not word in self.word2index:\n",
        "            self.word2index[word] = len(self.word2index)\n",
        "            self.index2word[len(self.index2word)] = word\n",
        "\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        '''\n",
        "        Add a sentence to the vocabulary\n",
        "        :param sentence: list of strings (words)\n",
        "        '''\n",
        "        # TODO add the sentence to the vocabulary, this method will call the add_word method\n",
        "        for word in sentence:\n",
        "            self.add_word(word)\n",
        "\n",
        "\n",
        "# Dataset class\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocabulary, pairs_refs, sentences):\n",
        "        # TODO We want vocabulary and pairs to be attributes of the class\n",
        "        self.vocabulary = vocabulary\n",
        "        self.pairs = pairs_refs\n",
        "        self.sentences = sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO how many pairs do we have?\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # TODO returns two tensors (question, answer) of the pair at index ix\n",
        "        # TODO the tensors should be of type torch.tensor and should contain integers (word indices)\n",
        "        q,a = self.pairs[ix]\n",
        "        q = torch.tensor([self.vocabulary.word2index[word] for word in self.sentences[q]])\n",
        "        a = torch.tensor([self.vocabulary.word2index[word] for word in [\"<SOS>\"]+self.sentences[a]])\n",
        "        return q,a\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Adapted from\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    '''\n",
        "    def __init__(self, d_model, dropout=0.0, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.max_len = max_len\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
        "                             * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        try:\n",
        "            assert x.size(0) < self.max_len\n",
        "        except:\n",
        "            print(\"The length of the sequence is bigger than the max_len of the positional encoding. Increase the max_len or provide a shorter sequence.\")\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=512, pad_id=0, encoder_layers=6, decoder_layers=6, dim_feedforward=2048, num_heads=8, dropout_transformer=0.1, dropout_posenconding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO add an embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # TODO add a positional encoding layer\n",
        "        self.pos_encoder = PositionalEncoding(d_model,dropout=dropout_posenconding)\n",
        "\n",
        "        # TODO add a transformer layer, you can use nn.Transformer. You can use the default values for the parameters, but what about batch_first?\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers=encoder_layers, num_decoder_layers=decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout_transformer, batch_first=True)\n",
        "\n",
        "        # TODO add a linear layer. Note: output should be probability distribution over the vocabulary\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "        # Stuff you may need\n",
        "        self.vocab_size = vocab_size\n",
        "        self.pad_id = pad_id\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "    def create_padding_mask(self, x, pad_id=0):\n",
        "        # TODO create a boolean mask for the <PAD> tokens\n",
        "        return x.eq(pad_id)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # S is the source sequence length, T is the target sequence length, N is the batch size, E is the feature number\n",
        "        # src: (N, S)\n",
        "        # tgt: (N, T)\n",
        "        # src_pad_mask: (N, S)\n",
        "        # tgt_pad_mask: (N, T)\n",
        "        # mask the future : (N * num_heads, T, T)\n",
        "\n",
        "        src_pad_mask = self.create_padding_mask(src, self.pad_id) # (N, S)\n",
        "        tgt_pad_mask = self.create_padding_mask(tgt, self.pad_id) # (N, T)\n",
        "\n",
        "        src = self.embedding(src)\n",
        "        tgt = self.embedding(tgt)\n",
        "\n",
        "        src = self.pos_encoder(src)  # (N, S, E)\n",
        "        tgt = self.pos_encoder(tgt) # (N, T, E)\n",
        "\n",
        "        # Mask the memory\n",
        "        memory_key_padding_mask = src_pad_mask  # (N, S)\n",
        "\n",
        "        # Mask the future\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1), dtype=torch.bool).to(tgt.device) # (T, T)\n",
        "\n",
        "        # Expand to make it N * num_heads, T, T\n",
        "        tgt_mask = tgt_mask.unsqueeze(0).repeat(tgt.size(0) * self.num_heads, 1, 1) # (N, T, T)\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask,tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=memory_key_padding_mask) # (N, T, E)\n",
        "        # Linear layer\n",
        "        output = self.linear(output) # (N, T, V)\n",
        "        return output\n",
        "\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "        self.best_model = None\n",
        "\n",
        "    def check_early_stop(self, current_loss, model):\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.counter = 0\n",
        "            self.best_model = model.state_dict()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        return self.early_stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Methods new\n",
        "############################\n",
        "def clear_punctuation(s):\n",
        "    '''\n",
        "    This function removes all the punctuation from a sentence and insert a blank between any letter and !?.\n",
        "    :param s: a string\n",
        "    :return: the \"cleaned\" string\n",
        "    '''\n",
        "    # Remove all the character that are not letters, puntuation or numbers\n",
        "    s = re.sub(r\"[^a-zA-Z.!?,']+\", r\" \", s)\n",
        "    # Insert a blank between any letter and !?. using regex\n",
        "    #s = re.sub(r\"([a-zA-Z])([!?.])\", r\"\\1 \\2\", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def pickle_dump(obj, PATH, name):\n",
        "    '''\n",
        "    Save an object to a pickle file\n",
        "    :param obj: object to save\n",
        "    :param path: path to the pickle file\n",
        "    '''\n",
        "    if not os.path.exists(PATH):\n",
        "        os.makedirs(PATH)\n",
        "\n",
        "    with open(PATH+name, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def pickle_load(PATH):\n",
        "    '''\n",
        "    Load an object from a pickle file\n",
        "    :param path: path to the pickle file\n",
        "    :return: the loaded object\n",
        "    '''\n",
        "    with open(PATH, 'rb') as f:\n",
        "        obj = pickle.load(f)\n",
        "    return obj\n",
        "\n",
        "def print_random_elements(collection, k=5):\n",
        "    '''\n",
        "    Print k random elements from a collection\n",
        "    :param collection: list of elements\n",
        "    :param k: number of elements to print\n",
        "    '''\n",
        "    random_elements = random.sample(collection, k=k)\n",
        "    for e in random_elements:\n",
        "        print(e)\n",
        "\n",
        "def collate_fn(batch,pad_idx):\n",
        "  data, targets = zip(*batch)\n",
        "  padded_data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=pad_idx)\n",
        "  padded_targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=pad_idx)\n",
        "  return padded_data, padded_targets\n",
        "\n",
        "def checkpoint(model,optimizer,path='./MyFiles/',save_name=None):\n",
        "  dic = {\n",
        "      'model_state' : model.state_dict(),\n",
        "      'optimizer' : optimizer.state_dict()\n",
        "  }\n",
        "  if save_name is not None:\n",
        "    torch.save(dic, path+save_name+\".pt\")\n",
        "  return dic\n",
        "\n",
        "def load_checkpoint(path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model_state = checkpoint['model_state']\n",
        "    optimizer_state = checkpoint['optimizer']\n",
        "    return model_state,optimizer_state\n",
        "\n",
        "def check_content_txt_files(convo_path, lines_path, num_elements):\n",
        "    '''\n",
        "    Check the content of the files\n",
        "    :param convo_path: path to the movie_conversations.txt file\n",
        "    :param lines_path: path to the movie_lines.txt file\n",
        "    :param num_elements: number of elements to print\n",
        "    '''\n",
        "    # Inspect movie_conversations.txt\n",
        "    with open(convo_path, 'r') as conv_file:\n",
        "        for i in range(num_elements):\n",
        "            line = conv_file.readline()\n",
        "\n",
        "    # Inspect movie_lines.txt\n",
        "    with open(lines_path, 'r') as lines_file:\n",
        "        for i in range(num_elements):\n",
        "            line = lines_file.readline()\n",
        "\n",
        "def get_reference_pairs(convo_path):\n",
        "    '''\n",
        "    Get the reference pairs\n",
        "    :return: a list of pairs of references of sentences\n",
        "    '''\n",
        "    ref_pairs = []\n",
        "    with open(convo_path, 'r') as conv_file:\n",
        "        for line in conv_file:\n",
        "            conversation = line.strip().split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").split(\",\")\n",
        "            for i in range(len(conversation) - 1):\n",
        "                ref_pairs.append((conversation[i].strip(), conversation[i+1].strip()))\n",
        "    return ref_pairs\n",
        "    \n",
        "\n",
        "def normalize_sentences(path_lines):\n",
        "    lines_dict = {}\n",
        "    empty_lines = 0\n",
        "    with open(path_lines, 'r', encoding='cp1252') as lines_file:\n",
        "        for full_line in lines_file:\n",
        "            line_split = full_line.split(' +++$+++ ')\n",
        "            line = line_split[-1]\n",
        "            line, is_line_empty = process_sentence(line)\n",
        "            if is_line_empty == 1:\n",
        "                empty_lines += 1\n",
        "            else:\n",
        "                lines_dict.update({line_split[0] : line})\n",
        "    return lines_dict, empty_lines\n",
        "\n",
        "def process_sentence(line):\n",
        "    is_line = 0\n",
        "    line = line.replace('\\n','').replace(\"<u>\",\"\").replace(\"</u>\",\"\").lower()\n",
        "    line = re.sub('-+','',line)\n",
        "    line = re.sub(r\"[^a-zA-Z.!?,']+\", r\" \", line)\n",
        "    line = re.sub(r\"i'm\", \"i am\", line, flags=re.I)\n",
        "    line = re.sub(r\"it's\", \"it is\", line, flags=re.I)\n",
        "    line = re.sub(r\"he's\", \"he is\", line, flags=re.I)\n",
        "    line = re.sub(r\"she's\", \"she is\", line, flags=re.I)\n",
        "    line = re.sub(r\"can't\", \"can not\", line, flags=re.I)\n",
        "    line = re.sub(r\"that's\", \"that is\", line, flags=re.I)\n",
        "    line = re.sub(r\"there's\", \"there is\", line, flags=re.I)\n",
        "    line = re.sub(r\"what's\", \"what is\", line, flags=re.I)\n",
        "    line = re.sub(r\"where's\", \"where is\", line, flags=re.I)\n",
        "    line = re.sub(r\"how's\", \"how is\", line, flags=re.I)\n",
        "    line = re.sub(r'\\.+(?:\\s*\\.{1,})+', '...', line, flags=re.I)\n",
        "    line = re.sub(r'!+(?:\\s*!{1,})+', '!', line, flags=re.I)\n",
        "    line = re.sub(r\"\\'ll\", \" will\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'em\", \" them\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'s\", \" is\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'ve\", \" have\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'re\", \" are\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'d\", \" would\", line, flags=re.I)\n",
        "    line = re.sub(r\"n't\", \" not\", line, flags=re.I)\n",
        "    line = re.sub(r\"won't\", \"will not\", line, flags=re.I)\n",
        "    line = re.sub(r\"can't\", \"cannot\", line, flags=re.I)\n",
        "    line = line.strip()\n",
        "    if line == '' or line.isspace():\n",
        "        is_line += 1\n",
        "    else:\n",
        "        line = TreebankWordTokenizer().tokenize(line)\n",
        "        if line[-1] not in ['.','!','?','...']:\n",
        "            line.append('.')\n",
        "    return line, is_line\n",
        "\n",
        "def get_valid_refs(ref_pairs, lines):\n",
        "    valid_refs = set()\n",
        "    for p in ref_pairs:\n",
        "        if p[0] in lines and p[1] in lines:\n",
        "            valid_refs.add(p[0])\n",
        "            valid_refs.add(p[1])\n",
        "    return valid_refs\n",
        "\n",
        "def generate_primitive_valid_pairs(all_ref_pairs, lines):\n",
        "    chosen_sentences = {}\n",
        "    chosen_ref_pairs = []\n",
        "\n",
        "    for p in all_ref_pairs:\n",
        "        if p[0] in lines and p[1] in lines:\n",
        "            chosen_sentences.update({p[0]: lines[p[0]]+['<EOS>'], p[1]: lines[p[1]]+['<EOS>']})\n",
        "            chosen_ref_pairs.append(p)\n",
        "    return chosen_sentences, chosen_ref_pairs\n",
        "\n",
        "def eliminate_long_sentences(chosen_sentences, chosen_ref_pairs, max_length):\n",
        "    rule_out_sentences_refs = set()\n",
        "    chosen_sentences2 = {}\n",
        "    chosen_ref_pairs2 = []\n",
        "\n",
        "    for k,v in chosen_sentences.items():\n",
        "        if len(v) > max_length:\n",
        "            rule_out_sentences_refs.add(k)\n",
        "\n",
        "    for p in chosen_ref_pairs:\n",
        "        if p[0] not in rule_out_sentences_refs and p[1] not in rule_out_sentences_refs:\n",
        "            chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "            chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "            chosen_ref_pairs2.append(p)\n",
        "\n",
        "    return chosen_sentences2,chosen_ref_pairs2,rule_out_sentences_refs\n",
        "\n",
        "def eliminate_sentences_with_rare_words(chosen_sentences, chosen_ref_pairs, rule_out_words):\n",
        "    rule_out_sentences_refs = set()\n",
        "    chosen_sentences2 = {}\n",
        "    chosen_ref_pairs2 = []\n",
        "\n",
        "    for k,v in chosen_sentences.items():\n",
        "        if any(word in rule_out_words for word in v):\n",
        "            rule_out_sentences_refs.add(k)\n",
        "\n",
        "    for p in chosen_ref_pairs:\n",
        "        if p[0] not in rule_out_sentences_refs and p[1] not in rule_out_sentences_refs:\n",
        "            chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "            chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "            chosen_ref_pairs2.append(p)\n",
        "\n",
        "    return chosen_sentences2,chosen_ref_pairs2,rule_out_sentences_refs\n",
        "\n",
        "def count_words(chosen_ref_pairs, chosen_sentences):\n",
        "    word_counts = {}\n",
        "    for p in chosen_ref_pairs:\n",
        "        for r in p:\n",
        "            for w in chosen_sentences[r]:\n",
        "                if w in word_counts:\n",
        "                    word_counts[w] += 1\n",
        "                else:\n",
        "                    word_counts[w] = 1\n",
        "    num_words = sum(word_counts.values())\n",
        "    return word_counts, num_words\n",
        "\n",
        "\n",
        "def extract_sentences_from_refs(chosen_ref_pairs, chosen_sentences):\n",
        "    chosen_sentences2 = {}\n",
        "    for p in chosen_ref_pairs:\n",
        "        chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "        chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "    return chosen_sentences2 \n",
        "\n",
        "\n",
        "def create_pairs(path='./MyFiles/',savename=\"result\",max_length=26,word_frequency_discard=10,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "        check_content_txt_files('./Data/movie_conversations.txt', './Data/movie_lines.txt', 5)\n",
        "\n",
        "    all_ref_pairs = get_reference_pairs('./Data/movie_conversations.txt')\n",
        "\n",
        "    if verbose:\n",
        "        print_random_elements(all_ref_pairs)\n",
        "\n",
        "    lines,empty_lines = normalize_sentences('./Data/movie_lines.txt')\n",
        "\n",
        "    if verbose:\n",
        "        print('Number of empty lines: {}'.format(empty_lines))\n",
        "        print_random_elements(list(lines.values()))\n",
        "\n",
        "    chosen_sentences, chosen_ref_pairs = generate_primitive_valid_pairs(all_ref_pairs, lines)\n",
        "\n",
        "    if verbose:\n",
        "        print_random_elements(chosen_ref_pairs)\n",
        "\n",
        "        # Filter out the sentences that are too long\n",
        "        # Compute the length of each sentence\n",
        "        # Compute the mean and standard deviation for sentence lengths\n",
        "        sentence_lengths = []\n",
        "        for p in chosen_ref_pairs:\n",
        "            sentence_lengths.append(len(chosen_sentences[p[0]]))\n",
        "            sentence_lengths.append(len(chosen_sentences[p[1]]))\n",
        "\n",
        "        mean_length = statistics.mean(sentence_lengths)\n",
        "        std_dev = statistics.stdev(sentence_lengths)\n",
        "\n",
        "        print('Mean sentence length: {}'.format(mean_length))\n",
        "        print('Standard deviation: {}'.format(std_dev))\n",
        "        print('Max sentence length: {}'.format(max(sentence_lengths)))\n",
        "        print('Min sentence length: {}'.format(min(sentence_lengths)))\n",
        "\n",
        "        # Plot the histogram with logarithmic scale on the y-axis\n",
        "        plt.hist(sentence_lengths, density=True, bins=40)\n",
        "        plt.xlabel('Sentence Length')\n",
        "        plt.ylabel('Frequency (log scale)')\n",
        "        plt.title('Sentence Length Distribution')\n",
        "        plt.yscale('log')  # Set y-axis scale to logarithmic\n",
        "        plt.axvline(x=mean_length, color='r', linestyle='--', label='Mean')  # Add vertical line for the mean\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        # Compute the frequency of each sentence length\n",
        "        length_counts = {}\n",
        "        for length in sentence_lengths:\n",
        "            if length in length_counts:\n",
        "                length_counts[length] += 1\n",
        "            else:\n",
        "                length_counts[length] = 1\n",
        "\n",
        "        # Sort the sentence lengths in ascending order\n",
        "        sorted_lengths = sorted(length_counts.keys())\n",
        "\n",
        "        # Compute the accumulated frequency percentage\n",
        "        total_sentences = len(sentence_lengths)\n",
        "        accumulated_percentage = 0\n",
        "        percentage_values = []\n",
        "        for length in sorted_lengths:\n",
        "            frequency = length_counts[length]\n",
        "            percentage = (frequency / total_sentences) * 100\n",
        "            accumulated_percentage += percentage\n",
        "            percentage_values.append(accumulated_percentage)\n",
        "\n",
        "        # Plot the sentence lengths and their accumulated frequency percentage\n",
        "        plt.plot(sorted_lengths, percentage_values)\n",
        "        plt.xlabel('Sentence Length')\n",
        "        plt.ylabel('Accumulated Frequency Percentage')\n",
        "        plt.title('Sentence Length Distribution')\n",
        "        plt.show()\n",
        "\n",
        "    initial_num_sentences = len(chosen_sentences)\n",
        "    initial_num_pairs = len(chosen_ref_pairs)\n",
        "    chosen_sentences2,chosen_ref_pairs2,rule_out_sentences_refs = eliminate_long_sentences(chosen_sentences, chosen_ref_pairs, max_length) \n",
        "\n",
        "    if verbose:\n",
        "        print('Initial number of sentences: {}'.format(initial_num_sentences))\n",
        "        print('Current number of senteces: {}'.format(initial_num_sentences-len(rule_out_sentences_refs)))\n",
        "        print('Initial number of pairs: {}'.format(initial_num_pairs))\n",
        "        print('Current number of pairs: {}'.format(initial_num_pairs-len(chosen_ref_pairs2)))\n",
        "\n",
        "\n",
        "    word_counts, num_words = count_words(chosen_ref_pairs2, chosen_sentences2)\n",
        "\n",
        "    if verbose:\n",
        "        print('Number of words: {}'.format(num_words))\n",
        "        print('Number of unique words: {}'.format(len(word_counts)))\n",
        "\n",
        "        plt.plot(range(len(word_counts)), list(word_counts.values()))\n",
        "        plt.xlabel('Word index')\n",
        "        plt.ylabel('Word frequency')\n",
        "        plt.suptitle('Word frequency distribution')\n",
        "        plt.title('Frequency per word')\n",
        "        plt.show()\n",
        "\n",
        "        # Compute the mean and standard deviation for word counts\n",
        "        mean_value = statistics.mean(word_counts.values())\n",
        "        print(\"Mean value:\", mean_value)\n",
        "        print(\"Max value:\", max(word_counts.values()))\n",
        "        print(\"Min value:\", min(word_counts.values()))\n",
        "\n",
        "        # Plot the distribution of word counts < mean\n",
        "        dict_lower_mean = {k: v for k, v in word_counts.items() if v < mean_value}\n",
        "        sorted_dict_lower_mean = dict(sorted(dict_lower_mean.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        plt.plot(range(len(sorted_dict_lower_mean)), sorted_dict_lower_mean.values())\n",
        "        plt.xlabel('Word index')\n",
        "        plt.ylabel('Word count')\n",
        "        plt.suptitle('Word count distribution')\n",
        "        plt.title('Words with count < mean')\n",
        "        plt.show()\n",
        "\n",
        "    # Frequency threshold and filter out the words that are too rare\n",
        "    rule_out_words = [k for k, v in word_counts.items() if v < word_frequency_discard]\n",
        "    chosen_sentences3,chosen_ref_pairs3,rule_out_sentences_refs = eliminate_sentences_with_rare_words(chosen_sentences2, chosen_ref_pairs2, rule_out_words)\n",
        "\n",
        "    if verbose:\n",
        "        print('Current number of senteces: {} ({:.2f}% of total)'.format(initial_num_sentences-len(chosen_sentences3),(initial_num_sentences-len(chosen_sentences3))/initial_num_sentences*100))\n",
        "        print('Current number of pairs: {} ({:.2f}% of total)'.format(initial_num_pairs-len(chosen_ref_pairs3),(initial_num_pairs-len(chosen_ref_pairs3))/initial_num_pairs*100))\n",
        "\n",
        "    # Save the pairs to a pickle file\n",
        "\n",
        "\n",
        "    pickle_dump(chosen_sentences3,path,savename+\"_sentences.pkl\")\n",
        "    pickle_dump(chosen_ref_pairs3,path,savename+\"_ref_pairs.pkl\")\n",
        "\n",
        "    return chosen_sentences3,chosen_ref_pairs3\n",
        "\n",
        "\n",
        "def train_with_gradient_accumulation(epochs, model, criterion, optimizer, train_loader, device, val_loader, accumulation_batches, lr_scheduler, print_every_n_batches=32):\n",
        "\n",
        "    assert  print_every_n_batches % accumulation_batches == 0, \"print_every_n_batches must be a multiple of accumulation_batches\"\n",
        "    assert  len(train_loader) % print_every_n_batches == 0, \"print_every_n_batches must be a multiple of len(train_loader)\"\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    vocab = train_loader.dataset.vocabulary\n",
        "    optimizer.zero_grad()\n",
        "    running_loss = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (data, targets) in enumerate(train_loader):\n",
        "          model.train()\n",
        "          data = data.to(device)\n",
        "          targets = targets.to(device)\n",
        "          outputs = model(data,targets[:,:-1])\n",
        "          loss = criterion(outputs.reshape(-1,outputs.size(-1)), targets[:,1:].reshape(-1))\n",
        "          loss = loss / accumulation_batches\n",
        "          running_loss += loss.item()\n",
        "          loss.backward()\n",
        "\n",
        "          if (i+1) % accumulation_batches == 0 or i + 1 == len(train_loader):\n",
        "              train_losses.append(running_loss)\n",
        "              running_loss = 0\n",
        "              optimizer.step()\n",
        "              if lr_scheduler:\n",
        "                lr_scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "          if (i+1) % print_every_n_batches == 0 or i + 1 == len(train_loader):\n",
        "              model.eval()\n",
        "              total_loss = 0  \n",
        "              with torch.no_grad():\n",
        "                  for data, targets in val_loader:\n",
        "                      data = data.to(device)\n",
        "                      targets = targets.to(device)\n",
        "                      outputs = model(data,targets[:,:-1])\n",
        "                      loss = criterion(outputs.reshape(-1,outputs.size(-1)), targets[:,1:].reshape(-1))\n",
        "                      total_loss += loss.item()\n",
        "                  val_losses.append(total_loss / len(val_loader))  \n",
        "              model.train()\n",
        "\n",
        "              random_index = random.randint(0, len(targets)-1)\n",
        "              target_sentence = \" \".join([vocab.index2word[idx.item()] for idx in targets[random_index][1:]])\n",
        "              output_sentence = \" \".join([vocab.index2word[idx.item()] for idx in outputs.argmax(dim=-1)[random_index]])\n",
        "\n",
        "              print(f\"Epoch: {epoch+1}/{epochs}, Batch: {i+1}/{len(train_loader)}\")\n",
        "              print(f\"Train Loss: {train_losses[-1]:.4f}\")\n",
        "              print(f\"Validation Loss: {val_losses[-1]:.4f}\")\n",
        "              print(f\"Random Target Sentence: {target_sentence}\")\n",
        "              print(f\"Random Output Sentence: {output_sentence}\\n\")\n",
        "\n",
        "    return train_losses, val_losses, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !!! Don't change the seed !!!\n",
        "torch.manual_seed(42)\n",
        "# !!!!!!\n",
        "\n",
        "\n",
        "# Load pairs\n",
        "PATH = './MyFiles/'\n",
        "chosen_sentences = pickle_load(PATH+'result_sentences.pkl')\n",
        "chosen_ref_pairs = pickle_load(PATH+'result_ref_pairs.pkl')\n",
        "\n",
        "# Pipeline parameters\n",
        "############################\n",
        "# Hyperparameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128 #128 batches\n",
        "accumulation_batches = 16 #64 updates per epoch\n",
        "rand_sample_num = 40960\n",
        "learning_rate = 1e-4\n",
        "d_model = 512 #768\n",
        "encoder_layers = 6\n",
        "decoder_layers = 5\n",
        "feed_forward_dim = 2048\n",
        "nheads = 8\n",
        "dropout_transformer = 0.2\n",
        "dropout_posenconding = 0\n",
        "patience = 3\n",
        "epochs = 10\n",
        "print_every_n_batches = 32\n",
        "\n",
        "# Randomly sample pairs and splits\n",
        "rand_sample_num = min(rand_sample_num,len(chosen_ref_pairs))\n",
        "chosen_ref_pairs = random.sample(chosen_ref_pairs,rand_sample_num)\n",
        "train_size = (int(0.8 * rand_sample_num)//batch_size)*batch_size\n",
        "val_size = (rand_sample_num-train_size)//2\n",
        "test_size = rand_sample_num-train_size-val_size\n",
        "train_pairs, test_pairs, val_pairs = random_split(chosen_ref_pairs,[train_size,val_size,test_size])\n",
        "\n",
        "# Vocabulary, Dataset and Dataloader\n",
        "vocab = Vocabulary(\"English\",chosen_sentences.values())\n",
        "train_dataset = Dataset(vocab,train_pairs,extract_sentences_from_refs(train_pairs, chosen_sentences))\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))\n",
        "val_dataset = Dataset(vocab,val_pairs,extract_sentences_from_refs(val_pairs, chosen_sentences))\n",
        "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))\n",
        "\n",
        "\n",
        "# Pipeline initialization\n",
        "############################\n",
        "# Model, criterion, optimizer and scheduler\n",
        "model = TransformerModel(vocab_size=len(vocab.word2index),d_model=d_model,pad_id=vocab.word2index[\"<PAD>\"],\n",
        "                        encoder_layers=encoder_layers,decoder_layers=decoder_layers,dim_feedforward=feed_forward_dim,\n",
        "                        num_heads=nheads,dropout_transformer=dropout_transformer, dropout_posenconding=dropout_posenconding).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9, verbose=False)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=10, factor=0.8)\n",
        "stopper = EarlyStopper(patience=patience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64.0\n",
            "8.0\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader)/accumulation_batches) # updates/logs per epoch\n",
        "print(len(train_loader)/print_every_n_batches) # logs per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10, Batch: 16/256\n",
            "Train Loss: 9.5964\n",
            "Validation Loss: 9.6061\n",
            "Random Target Sentence: nothing . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: common conway conway conway punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish punish\n",
            "\n",
            "Epoch: 1/10, Batch: 32/256\n",
            "Train Loss: 6.0273\n",
            "Validation Loss: 5.3162\n",
            "Random Target Sentence: your valet , sir . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 48/256\n",
            "Train Loss: 4.6723\n",
            "Validation Loss: 4.1133\n",
            "Random Target Sentence: rules are made to be broken . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 64/256\n",
            "Train Loss: 4.1220\n",
            "Validation Loss: 4.0184\n",
            "Random Target Sentence: they are stealing my chopper ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 80/256\n",
            "Train Loss: 3.9895\n",
            "Validation Loss: 4.1379\n",
            "Random Target Sentence: that is the idea . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 96/256\n",
            "Train Loss: 3.8893\n",
            "Validation Loss: 4.1797\n",
            "Random Target Sentence: right. she had a friend with her. the friend took off . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 112/256\n",
            "Train Loss: 3.9634\n",
            "Validation Loss: 4.1266\n",
            "Random Target Sentence: where were you , jake ? where have you been ? why have not you called ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 128/256\n",
            "Train Loss: 3.7705\n",
            "Validation Loss: 3.9972\n",
            "Random Target Sentence: as much as you used to ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 144/256\n",
            "Train Loss: 3.7811\n",
            "Validation Loss: 3.8414\n",
            "Random Target Sentence: yah . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 160/256\n",
            "Train Loss: 3.8236\n",
            "Validation Loss: 3.7101\n",
            "Random Target Sentence: i can see that but where ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 176/256\n",
            "Train Loss: 3.7291\n",
            "Validation Loss: 3.6305\n",
            "Random Target Sentence: no. you killed her. manager remembers you going into her room. your fingerprints were found all over the place . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 192/256\n",
            "Train Loss: 3.6646\n",
            "Validation Loss: 3.5873\n",
            "Random Target Sentence: there . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 208/256\n",
            "Train Loss: 3.6329\n",
            "Validation Loss: 3.5661\n",
            "Random Target Sentence: but who what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 224/256\n",
            "Train Loss: 3.5804\n",
            "Validation Loss: 3.5588\n",
            "Random Target Sentence: no , man. i know you did not get it 'cause you would not have asked me. it was not that funny anyway ... <EOS>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 240/256\n",
            "Train Loss: 3.5151\n",
            "Validation Loss: 3.5505\n",
            "Random Target Sentence: what list ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 1/10, Batch: 256/256\n",
            "Train Loss: 3.5391\n",
            "Validation Loss: 3.5308\n",
            "Random Target Sentence: let her go ! let her go ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 16/256\n",
            "Train Loss: 3.5609\n",
            "Validation Loss: 3.4952\n",
            "Random Target Sentence: i am not jealous ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 32/256\n",
            "Train Loss: 3.3969\n",
            "Validation Loss: 3.4472\n",
            "Random Target Sentence: just a girl . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 48/256\n",
            "Train Loss: 3.4224\n",
            "Validation Loss: 3.3975\n",
            "Random Target Sentence: it is in the report . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 64/256\n",
            "Train Loss: 3.4666\n",
            "Validation Loss: 3.3523\n",
            "Random Target Sentence: the answer is not in the box. it is in the band . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 80/256\n",
            "Train Loss: 3.4069\n",
            "Validation Loss: 3.3141\n",
            "Random Target Sentence: well , let is see what we get . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 96/256\n",
            "Train Loss: 3.3000\n",
            "Validation Loss: 3.2843\n",
            "Random Target Sentence: that is it . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 112/256\n",
            "Train Loss: 3.3750\n",
            "Validation Loss: 3.2630\n",
            "Random Target Sentence: yeah , right. even i can barely read all my work . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 128/256\n",
            "Train Loss: 3.3373\n",
            "Validation Loss: 3.2468\n",
            "Random Target Sentence: david ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 144/256\n",
            "Train Loss: 3.2490\n",
            "Validation Loss: 3.2333\n",
            "Random Target Sentence: but he was just another feller , was not he ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 160/256\n",
            "Train Loss: 3.3237\n",
            "Validation Loss: 3.2202\n",
            "Random Target Sentence: hmm ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 176/256\n",
            "Train Loss: 3.2654\n",
            "Validation Loss: 3.2000\n",
            "Random Target Sentence: day jobs , yeah. i have tried them. turn right . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 192/256\n",
            "Train Loss: 3.2437\n",
            "Validation Loss: 3.1719\n",
            "Random Target Sentence: let her go ! let her go ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 208/256\n",
            "Train Loss: 3.1342\n",
            "Validation Loss: 3.1363\n",
            "Random Target Sentence: someone is trying to destroy my life , and i would like to find out who . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 224/256\n",
            "Train Loss: 3.1948\n",
            "Validation Loss: 3.0986\n",
            "Random Target Sentence: what are you talking about ? this is the new mac. you a hacker ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 240/256\n",
            "Train Loss: 3.1656\n",
            "Validation Loss: 3.0595\n",
            "Random Target Sentence: for killing a man . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 2/10, Batch: 256/256\n",
            "Train Loss: 3.1257\n",
            "Validation Loss: 3.0212\n",
            "Random Target Sentence: yeah , lung cancer. ten years ago . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 16/256\n",
            "Train Loss: 3.0359\n",
            "Validation Loss: 2.9841\n",
            "Random Target Sentence: i am pregnant . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 32/256\n",
            "Train Loss: 3.0611\n",
            "Validation Loss: 2.9478\n",
            "Random Target Sentence: yeah ... you know ... fucking . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 48/256\n",
            "Train Loss: 3.1085\n",
            "Validation Loss: 2.9051\n",
            "Random Target Sentence: i have not got time for this . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 64/256\n",
            "Train Loss: 2.9767\n",
            "Validation Loss: 2.8425\n",
            "Random Target Sentence: yes , sam is tough alright . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 80/256\n",
            "Train Loss: 2.9065\n",
            "Validation Loss: 2.7516\n",
            "Random Target Sentence: about to hang himself , i should think . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 96/256\n",
            "Train Loss: 2.7288\n",
            "Validation Loss: 2.6322\n",
            "Random Target Sentence: what does it say . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 112/256\n",
            "Train Loss: 2.7852\n",
            "Validation Loss: 2.5161\n",
            "Random Target Sentence: twelve seconds ... ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 128/256\n",
            "Train Loss: 2.6406\n",
            "Validation Loss: 2.4319\n",
            "Random Target Sentence: all right ... let is go . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <PAD> <PAD> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 144/256\n",
            "Train Loss: 2.5841\n",
            "Validation Loss: 2.3813\n",
            "Random Target Sentence: what about the money ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 160/256\n",
            "Train Loss: 2.4274\n",
            "Validation Loss: 2.3549\n",
            "Random Target Sentence: i can see that but where ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 176/256\n",
            "Train Loss: 2.5017\n",
            "Validation Loss: 2.3383\n",
            "Random Target Sentence: bye . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 192/256\n",
            "Train Loss: 2.4503\n",
            "Validation Loss: 2.3201\n",
            "Random Target Sentence: a fair number , ma . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 208/256\n",
            "Train Loss: 2.4673\n",
            "Validation Loss: 2.2952\n",
            "Random Target Sentence: as much as you used to ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 224/256\n",
            "Train Loss: 2.3230\n",
            "Validation Loss: 2.2689\n",
            "Random Target Sentence: i am not jealous ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 240/256\n",
            "Train Loss: 2.3299\n",
            "Validation Loss: 2.2454\n",
            "Random Target Sentence: i can see that but where ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 3/10, Batch: 256/256\n",
            "Train Loss: 2.3085\n",
            "Validation Loss: 2.2255\n",
            "Random Target Sentence: all right , tell us , rose , what makes you think you are pregnant ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 16/256\n",
            "Train Loss: 2.3661\n",
            "Validation Loss: 2.2082\n",
            "Random Target Sentence: that is what i think . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 32/256\n",
            "Train Loss: 2.2753\n",
            "Validation Loss: 2.1927\n",
            "Random Target Sentence: i have not got time for this . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 48/256\n",
            "Train Loss: 2.2085\n",
            "Validation Loss: 2.1784\n",
            "Random Target Sentence: what are you trying to say ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 64/256\n",
            "Train Loss: 2.2427\n",
            "Validation Loss: 2.1647\n",
            "Random Target Sentence: well , let is see what we get . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 80/256\n",
            "Train Loss: 2.2321\n",
            "Validation Loss: 2.1514\n",
            "Random Target Sentence: someone is trying to destroy my life , and i would like to find out who . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 96/256\n",
            "Train Loss: 2.2786\n",
            "Validation Loss: 2.1390\n",
            "Random Target Sentence: just checking out the lights . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 112/256\n",
            "Train Loss: 2.1855\n",
            "Validation Loss: 2.1274\n",
            "Random Target Sentence: i am fucking serious. where is telly ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 128/256\n",
            "Train Loss: 2.2094\n",
            "Validation Loss: 2.1169\n",
            "Random Target Sentence: but he was just another feller , was not he ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 144/256\n",
            "Train Loss: 2.1807\n",
            "Validation Loss: 2.1071\n",
            "Random Target Sentence: let her go ! let her go ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 160/256\n",
            "Train Loss: 2.1305\n",
            "Validation Loss: 2.0979\n",
            "Random Target Sentence: wilson yeah yeah i fought wilson . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 176/256\n",
            "Train Loss: 2.0916\n",
            "Validation Loss: 2.0893\n",
            "Random Target Sentence: as much as you used to ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 192/256\n",
            "Train Loss: 2.1206\n",
            "Validation Loss: 2.0816\n",
            "Random Target Sentence: thank you. tell me what do those words mean ? beloved husband ... beloved son ... beloved wife ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 208/256\n",
            "Train Loss: 2.1795\n",
            "Validation Loss: 2.0741\n",
            "Random Target Sentence: then show me how . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 224/256\n",
            "Train Loss: 2.0547\n",
            "Validation Loss: 2.0667\n",
            "Random Target Sentence: yeah , right. even i can barely read all my work . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 240/256\n",
            "Train Loss: 2.1033\n",
            "Validation Loss: 2.0594\n",
            "Random Target Sentence: as much as you used to ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 4/10, Batch: 256/256\n",
            "Train Loss: 2.1277\n",
            "Validation Loss: 2.0521\n",
            "Random Target Sentence: no. you killed her. manager remembers you going into her room. your fingerprints were found all over the place . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 16/256\n",
            "Train Loss: 2.1197\n",
            "Validation Loss: 2.0447\n",
            "Random Target Sentence: yes , his girlfriend . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 32/256\n",
            "Train Loss: 2.0967\n",
            "Validation Loss: 2.0373\n",
            "Random Target Sentence: with pleasure , madame ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 48/256\n",
            "Train Loss: 2.1229\n",
            "Validation Loss: 2.0301\n",
            "Random Target Sentence: they are stealing my chopper ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 64/256\n",
            "Train Loss: 1.9835\n",
            "Validation Loss: 2.0235\n",
            "Random Target Sentence: right. she had a friend with her. the friend took off . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 80/256\n",
            "Train Loss: 1.9913\n",
            "Validation Loss: 2.0172\n",
            "Random Target Sentence: thank you. tell me what do those words mean ? beloved husband ... beloved son ... beloved wife ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 96/256\n",
            "Train Loss: 2.0547\n",
            "Validation Loss: 2.0116\n",
            "Random Target Sentence: right. she had a friend with her. the friend took off . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 112/256\n",
            "Train Loss: 2.0233\n",
            "Validation Loss: 2.0059\n",
            "Random Target Sentence: what are you trying to say ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 128/256\n",
            "Train Loss: 2.0696\n",
            "Validation Loss: 1.9993\n",
            "Random Target Sentence: i am not jealous ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 144/256\n",
            "Train Loss: 2.0674\n",
            "Validation Loss: 1.9914\n",
            "Random Target Sentence: just a girl . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 160/256\n",
            "Train Loss: 2.0545\n",
            "Validation Loss: 1.9822\n",
            "Random Target Sentence: let her go ! let her go ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 176/256\n",
            "Train Loss: 2.0147\n",
            "Validation Loss: 1.9726\n",
            "Random Target Sentence: do not tell me you were worried ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . <EOS> . <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 192/256\n",
            "Train Loss: 2.0292\n",
            "Validation Loss: 1.9641\n",
            "Random Target Sentence: just a girl . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 208/256\n",
            "Train Loss: 1.9866\n",
            "Validation Loss: 1.9567\n",
            "Random Target Sentence: you would say anything to keep me away from her. to keep her for yourself . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . <EOS> <EOS> . <EOS> . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 224/256\n",
            "Train Loss: 2.0058\n",
            "Validation Loss: 1.9495\n",
            "Random Target Sentence: but who what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 240/256\n",
            "Train Loss: 1.9951\n",
            "Validation Loss: 1.9410\n",
            "Random Target Sentence: no . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 5/10, Batch: 256/256\n",
            "Train Loss: 2.0004\n",
            "Validation Loss: 1.9327\n",
            "Random Target Sentence: sure . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 16/256\n",
            "Train Loss: 1.9467\n",
            "Validation Loss: 1.9263\n",
            "Random Target Sentence: yes , sam is tough alright . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 32/256\n",
            "Train Loss: 1.9486\n",
            "Validation Loss: 1.9209\n",
            "Random Target Sentence: you are in quite a mood today . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 48/256\n",
            "Train Loss: 1.9908\n",
            "Validation Loss: 1.9160\n",
            "Random Target Sentence: quiet . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 64/256\n",
            "Train Loss: 1.9799\n",
            "Validation Loss: 1.9117\n",
            "Random Target Sentence: good. i am glad that is settled ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 80/256\n",
            "Train Loss: 1.9478\n",
            "Validation Loss: 1.9086\n",
            "Random Target Sentence: well , let is see what we get . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 96/256\n",
            "Train Loss: 1.9817\n",
            "Validation Loss: 1.9065\n",
            "Random Target Sentence: that is all right , eric . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 112/256\n",
            "Train Loss: 1.8959\n",
            "Validation Loss: 1.9048\n",
            "Random Target Sentence: rules are made to be broken . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 128/256\n",
            "Train Loss: 1.9099\n",
            "Validation Loss: 1.9033\n",
            "Random Target Sentence: what are you talking about ? this is the new mac. you a hacker ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . <EOS> . . . . . . . <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 144/256\n",
            "Train Loss: 1.9947\n",
            "Validation Loss: 1.9016\n",
            "Random Target Sentence: my point , well ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 160/256\n",
            "Train Loss: 1.9385\n",
            "Validation Loss: 1.8998\n",
            "Random Target Sentence: do not tell me you were worried ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 176/256\n",
            "Train Loss: 1.8860\n",
            "Validation Loss: 1.8977\n",
            "Random Target Sentence: no , it would be spooky without the war give them back . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 192/256\n",
            "Train Loss: 1.9456\n",
            "Validation Loss: 1.8955\n",
            "Random Target Sentence: yes . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 208/256\n",
            "Train Loss: 1.8868\n",
            "Validation Loss: 1.8929\n",
            "Random Target Sentence: would you like the same suite ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 224/256\n",
            "Train Loss: 1.9223\n",
            "Validation Loss: 1.8897\n",
            "Random Target Sentence: did you actually give williams that gun ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 240/256\n",
            "Train Loss: 1.8800\n",
            "Validation Loss: 1.8864\n",
            "Random Target Sentence: i told you. she kills him . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 6/10, Batch: 256/256\n",
            "Train Loss: 1.9022\n",
            "Validation Loss: 1.8843\n",
            "Random Target Sentence: no. one of us is enough . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 16/256\n",
            "Train Loss: 1.9221\n",
            "Validation Loss: 1.8831\n",
            "Random Target Sentence: i am glad you are doing well . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 32/256\n",
            "Train Loss: 1.9339\n",
            "Validation Loss: 1.8823\n",
            "Random Target Sentence: no , it would be spooky without the war give them back . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 48/256\n",
            "Train Loss: 1.8263\n",
            "Validation Loss: 1.8815\n",
            "Random Target Sentence: i am pregnant . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 64/256\n",
            "Train Loss: 1.8660\n",
            "Validation Loss: 1.8809\n",
            "Random Target Sentence: no i do not. she worries about you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 80/256\n",
            "Train Loss: 1.8803\n",
            "Validation Loss: 1.8804\n",
            "Random Target Sentence: but i did not play with them , daddy. they would not play with me . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 96/256\n",
            "Train Loss: 1.9514\n",
            "Validation Loss: 1.8803\n",
            "Random Target Sentence: yeah sure. it is a real boy scout flashlight . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 112/256\n",
            "Train Loss: 1.9321\n",
            "Validation Loss: 1.8800\n",
            "Random Target Sentence: but i did not play with them , daddy. they would not play with me . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 128/256\n",
            "Train Loss: 1.9025\n",
            "Validation Loss: 1.8794\n",
            "Random Target Sentence: sure do not. mind if i ask where you got it ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 144/256\n",
            "Train Loss: 1.9284\n",
            "Validation Loss: 1.8783\n",
            "Random Target Sentence: no , sir. the other car ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 160/256\n",
            "Train Loss: 1.9046\n",
            "Validation Loss: 1.8767\n",
            "Random Target Sentence: bye . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 176/256\n",
            "Train Loss: 1.9142\n",
            "Validation Loss: 1.8749\n",
            "Random Target Sentence: no , we never did that . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 192/256\n",
            "Train Loss: 1.9260\n",
            "Validation Loss: 1.8734\n",
            "Random Target Sentence: otis ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 208/256\n",
            "Train Loss: 1.8890\n",
            "Validation Loss: 1.8721\n",
            "Random Target Sentence: yah . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 224/256\n",
            "Train Loss: 1.8730\n",
            "Validation Loss: 1.8711\n",
            "Random Target Sentence: yeah ... you know ... fucking . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> . . <EOS> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 240/256\n",
            "Train Loss: 1.8433\n",
            "Validation Loss: 1.8704\n",
            "Random Target Sentence: did you really ask ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 7/10, Batch: 256/256\n",
            "Train Loss: 1.8974\n",
            "Validation Loss: 1.8699\n",
            "Random Target Sentence: yah . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 16/256\n",
            "Train Loss: 1.9277\n",
            "Validation Loss: 1.8691\n",
            "Random Target Sentence: who said anything about killing ? just keep driving straight ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . <EOS> . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 32/256\n",
            "Train Loss: 1.8467\n",
            "Validation Loss: 1.8678\n",
            "Random Target Sentence: it is in the report . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 48/256\n",
            "Train Loss: 1.8681\n",
            "Validation Loss: 1.8665\n",
            "Random Target Sentence: but i did not play with them , daddy. they would not play with me . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 64/256\n",
            "Train Loss: 1.9161\n",
            "Validation Loss: 1.8652\n",
            "Random Target Sentence: just checking out the lights . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 80/256\n",
            "Train Loss: 1.8364\n",
            "Validation Loss: 1.8640\n",
            "Random Target Sentence: did you actually give williams that gun ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 96/256\n",
            "Train Loss: 1.9268\n",
            "Validation Loss: 1.8628\n",
            "Random Target Sentence: did you actually give williams that gun ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 112/256\n",
            "Train Loss: 1.8841\n",
            "Validation Loss: 1.8615\n",
            "Random Target Sentence: all right ... let is go . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . <EOS> . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 128/256\n",
            "Train Loss: 1.8989\n",
            "Validation Loss: 1.8603\n",
            "Random Target Sentence: did you actually give williams that gun ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 144/256\n",
            "Train Loss: 1.8625\n",
            "Validation Loss: 1.8590\n",
            "Random Target Sentence: canada . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 160/256\n",
            "Train Loss: 1.8687\n",
            "Validation Loss: 1.8576\n",
            "Random Target Sentence: i did not mean it nothin ' dirty . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 176/256\n",
            "Train Loss: 1.8945\n",
            "Validation Loss: 1.8560\n",
            "Random Target Sentence: i said i found a room . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 192/256\n",
            "Train Loss: 1.8664\n",
            "Validation Loss: 1.8545\n",
            "Random Target Sentence: my point , well ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 208/256\n",
            "Train Loss: 1.8772\n",
            "Validation Loss: 1.8530\n",
            "Random Target Sentence: they called here after you left ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 224/256\n",
            "Train Loss: 1.8706\n",
            "Validation Loss: 1.8518\n",
            "Random Target Sentence: yes , his girlfriend . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 240/256\n",
            "Train Loss: 1.9299\n",
            "Validation Loss: 1.8510\n",
            "Random Target Sentence: thank you. tell me what do those words mean ? beloved husband ... beloved son ... beloved wife ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . . . . <EOS> . . <EOS> . . <EOS> . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 8/10, Batch: 256/256\n",
            "Train Loss: 1.8327\n",
            "Validation Loss: 1.8501\n",
            "Random Target Sentence: it is in the report . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 16/256\n",
            "Train Loss: 1.8699\n",
            "Validation Loss: 1.8494\n",
            "Random Target Sentence: but i did not play with them , daddy. they would not play with me . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i i . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 32/256\n",
            "Train Loss: 1.8736\n",
            "Validation Loss: 1.8481\n",
            "Random Target Sentence: with pleasure , madame ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 48/256\n",
            "Train Loss: 1.8208\n",
            "Validation Loss: 1.8467\n",
            "Random Target Sentence: twelve seconds ... ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 64/256\n",
            "Train Loss: 1.8780\n",
            "Validation Loss: 1.8455\n",
            "Random Target Sentence: your valet , sir . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you . i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 80/256\n",
            "Train Loss: 1.7961\n",
            "Validation Loss: 1.8449\n",
            "Random Target Sentence: you could charge him what you like . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 96/256\n",
            "Train Loss: 1.8743\n",
            "Validation Loss: 1.8451\n",
            "Random Target Sentence: you are not gon na be there . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 112/256\n",
            "Train Loss: 1.8744\n",
            "Validation Loss: 1.8453\n",
            "Random Target Sentence: yeah ... you know ... fucking . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> . . <EOS> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 128/256\n",
            "Train Loss: 1.9054\n",
            "Validation Loss: 1.8427\n",
            "Random Target Sentence: good. i am glad that is settled ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 144/256\n",
            "Train Loss: 1.8767\n",
            "Validation Loss: 1.8397\n",
            "Random Target Sentence: no. one of us is enough . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 160/256\n",
            "Train Loss: 1.8933\n",
            "Validation Loss: 1.8383\n",
            "Random Target Sentence: right. she had a friend with her. the friend took off . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 176/256\n",
            "Train Loss: 1.7946\n",
            "Validation Loss: 1.8383\n",
            "Random Target Sentence: all right ... let is go . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . <EOS> . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 192/256\n",
            "Train Loss: 1.8461\n",
            "Validation Loss: 1.8400\n",
            "Random Target Sentence: yes , sam is tough alright . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 208/256\n",
            "Train Loss: 1.8880\n",
            "Validation Loss: 1.8402\n",
            "Random Target Sentence: otis ... <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 224/256\n",
            "Train Loss: 1.8314\n",
            "Validation Loss: 1.8365\n",
            "Random Target Sentence: yeah , right. even i can barely read all my work . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . i . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 240/256\n",
            "Train Loss: 1.8903\n",
            "Validation Loss: 1.8329\n",
            "Random Target Sentence: just get there . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 9/10, Batch: 256/256\n",
            "Train Loss: 1.8665\n",
            "Validation Loss: 1.8308\n",
            "Random Target Sentence: about to hang himself , i should think . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you you . . you . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 16/256\n",
            "Train Loss: 1.8140\n",
            "Validation Loss: 1.8303\n",
            "Random Target Sentence: what are you talking about ? this is the new mac. you a hacker ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . . . <EOS> . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 32/256\n",
            "Train Loss: 1.7964\n",
            "Validation Loss: 1.8315\n",
            "Random Target Sentence: i ai not ever gon na fight joe louis , that is what is the matter . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . . . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 48/256\n",
            "Train Loss: 1.9227\n",
            "Validation Loss: 1.8309\n",
            "Random Target Sentence: but it is got teeth . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 64/256\n",
            "Train Loss: 1.8059\n",
            "Validation Loss: 1.8261\n",
            "Random Target Sentence: bye . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 80/256\n",
            "Train Loss: 1.8470\n",
            "Validation Loss: 1.8224\n",
            "Random Target Sentence: right. she had a friend with her. the friend took off . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you . . . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 96/256\n",
            "Train Loss: 1.8579\n",
            "Validation Loss: 1.8206\n",
            "Random Target Sentence: ... plenty . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i <EOS> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 112/256\n",
            "Train Loss: 1.8342\n",
            "Validation Loss: 1.8207\n",
            "Random Target Sentence: no , sir. the other car ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . i . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 128/256\n",
            "Train Loss: 1.8259\n",
            "Validation Loss: 1.8206\n",
            "Random Target Sentence: what are you talking about ? this is the new mac. you a hacker ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . ? . . <EOS> . . . . . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 144/256\n",
            "Train Loss: 1.8684\n",
            "Validation Loss: 1.8189\n",
            "Random Target Sentence: about to hang himself , i should think . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you . . . you . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 160/256\n",
            "Train Loss: 1.8125\n",
            "Validation Loss: 1.8145\n",
            "Random Target Sentence: did you have a good day ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you you . . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 176/256\n",
            "Train Loss: 1.9174\n",
            "Validation Loss: 1.8119\n",
            "Random Target Sentence: i am not jealous ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i i not . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 192/256\n",
            "Train Loss: 1.8570\n",
            "Validation Loss: 1.8107\n",
            "Random Target Sentence: come on ! <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 208/256\n",
            "Train Loss: 1.7857\n",
            "Validation Loss: 1.8104\n",
            "Random Target Sentence: about to hang himself , i should think . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i you you . . you not . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 224/256\n",
            "Train Loss: 1.8376\n",
            "Validation Loss: 1.8091\n",
            "Random Target Sentence: just get there . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 240/256\n",
            "Train Loss: 1.8535\n",
            "Validation Loss: 1.8058\n",
            "Random Target Sentence: hmm ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Epoch: 10/10, Batch: 256/256\n",
            "Train Loss: 1.8640\n",
            "Validation Loss: 1.8023\n",
            "Random Target Sentence: that is the idea . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Random Output Sentence: i is you . . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_losses, val_losses, model = train_with_gradient_accumulation(epochs, model, criterion, optimizer, train_loader,\n",
        "                                                                    device, val_loader, accumulation_batches, lr_scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch: 10/10, Batch: 256/256\n",
        "Train Loss: 1.5662\n",
        "Validation Loss: 1.5334\n",
        "Random Target Sentence: how much ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
        "Random Output Sentence: i do ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
        "\n",
        "# Hyperparameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128 #128 batches\n",
        "accumulation_batches = 4 #64 updates per epoch\n",
        "rand_sample_num = 40960\n",
        "learning_rate = 8e-4\n",
        "d_model = 512 #768\n",
        "encoder_layers = 6\n",
        "decoder_layers = 5\n",
        "feed_forward_dim = 2048\n",
        "nheads = 8\n",
        "dropout_transformer = 0.2\n",
        "dropout_posenconding = 0\n",
        "patience = 3\n",
        "epochs = 10\n",
        "print_every_n_batches = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot train losses and validation losses\n",
        "num = epochs*np.ceil(len(train_loader)/print_every_n_batches)\n",
        "plt.plot(np.linspace(1,num,len(train_losses)),train_losses, label='Train Loss')\n",
        "plt.plot(np.linspace(1,num,len(val_losses)),val_losses, label='Validation Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
