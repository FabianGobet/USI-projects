{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IQ-a3cM1EBhC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fabiangobet/anaconda3/envs/pythonProject/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Packages\n",
        "############################\n",
        "'''\n",
        "Template for the 4th assignment\n",
        "Student: Fabian Gobet\n",
        "'''\n",
        "import os\n",
        "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from accelerate import Accelerator\n",
        "import random\n",
        "import re\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "import statistics\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import itertools\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bPVvoUpsEBhD"
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "############################\n",
        "# Vocabulary class\n",
        "class Vocabulary:\n",
        "    '''\n",
        "    Class for dealing with our corpus\n",
        "    '''\n",
        "\n",
        "    def __init__(self, name, sentences):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            name (str): name of the language\n",
        "            pairs (list): list of pairs of sentences\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}\n",
        "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
        "        for s in sentences:\n",
        "            self.add_sentence(s)\n",
        "\n",
        "\n",
        "    def add_word(self, word):\n",
        "        '''\n",
        "        Add a word to the vocabulary\n",
        "        :param word: a string\n",
        "        '''\n",
        "        # TODO: add the word to the vocabulary\n",
        "        if not word in self.word2index:\n",
        "            self.word2index[word] = len(self.word2index)\n",
        "            self.index2word[len(self.index2word)] = word\n",
        "\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        '''\n",
        "        Add a sentence to the vocabulary\n",
        "        :param sentence: list of strings (words)\n",
        "        '''\n",
        "        # TODO add the sentence to the vocabulary, this method will call the add_word method\n",
        "        for word in sentence:\n",
        "            self.add_word(word)\n",
        "\n",
        "\n",
        "# Dataset class\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocabulary, pairs_refs, sentences):\n",
        "        # TODO We want vocabulary and pairs to be attributes of the class\n",
        "        self.vocabulary = vocabulary\n",
        "        self.pairs = pairs_refs\n",
        "        self.sentences = sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO how many pairs do we have?\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        # TODO returns two tensors (question, answer) of the pair at index ix\n",
        "        # TODO the tensors should be of type torch.tensor and should contain integers (word indices)\n",
        "        q,a = self.pairs[ix]\n",
        "        q = torch.tensor([self.vocabulary.word2index[word] for word in self.sentences[q]])\n",
        "        a = torch.tensor([self.vocabulary.word2index[word] for word in self.sentences[a]])\n",
        "        return q,a\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Adapted from\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    '''\n",
        "    def __init__(self, d_model, dropout=0.0, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.max_len = max_len\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
        "                             * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        try:\n",
        "            assert x.size(0) < self.max_len\n",
        "        except:\n",
        "            print(\"The length of the sequence is bigger than the max_len of the positional encoding. Increase the max_len or provide a shorter sequence.\")\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=512, pad_id=0, encoder_layers=6, decoder_layers=6, dim_feedforward=2048, num_heads=8, dropout_transformer=0.1, dropout_posenconding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO add an embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model,padding_idx=pad_id)\n",
        "\n",
        "        # TODO add a positional encoding layer\n",
        "        self.pos_encoder = PositionalEncoding(d_model,dropout=dropout_posenconding)\n",
        "\n",
        "        # TODO add a transformer layer, you can use nn.Transformer. You can use the default values for the parameters, but what about batch_first?\n",
        "        self.transformer = nn.Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers=encoder_layers, num_decoder_layers=decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout_transformer, batch_first=True)\n",
        "\n",
        "        # TODO add a linear layer. Note: output should be probability distribution over the vocabulary\n",
        "        self.linear = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Stuff you may need\n",
        "        self.vocab_size = vocab_size\n",
        "        self.pad_id = pad_id\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "    def create_padding_mask(self, x, pad_id=0):\n",
        "        # TODO create a boolean mask for the <PAD> tokens\n",
        "        return x.eq(pad_id)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # S is the source sequence length, T is the target sequence length, N is the batch size, E is the feature number\n",
        "        # src: (N, S)\n",
        "        # tgt: (N, T)\n",
        "        # src_pad_mask: (N, S)\n",
        "        # tgt_pad_mask: (N, T)\n",
        "        # mask the future : (N * num_heads, T, T)\n",
        "\n",
        "        src_pad_mask = self.create_padding_mask(src, self.pad_id) # (N, S)\n",
        "        tgt_pad_mask = self.create_padding_mask(tgt, self.pad_id) # (N, T)\n",
        "\n",
        "        src = self.embedding(src)\n",
        "        tgt = self.embedding(tgt)\n",
        "\n",
        "        src = self.pos_encoder(src)  # (N, S, E)\n",
        "        tgt = self.pos_encoder(tgt) # (N, T, E)\n",
        "\n",
        "        # Mask the memory\n",
        "        memory_key_padding_mask = src_pad_mask  # (N, S)\n",
        "\n",
        "        # Mask the future\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1), dtype=torch.bool).to(tgt.device) # (T, T)\n",
        "\n",
        "        # Expand to make it N * num_heads, T, T\n",
        "        tgt_mask = tgt_mask.unsqueeze(0).repeat(tgt.size(0) * self.num_heads, 1, 1) # (N, T, T)\n",
        "\n",
        "        # Transformer\n",
        "        output = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask,tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=memory_key_padding_mask) # (N, T, E)\n",
        "        # Linear layer\n",
        "        output = self.linear(output) # (N, T, V)\n",
        "        return output\n",
        "\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "        self.best_model = None\n",
        "\n",
        "    def check_early_stop(self, current_loss, model):\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.counter = 0\n",
        "            self.best_model = model.state_dict()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        return self.early_stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Methods new\n",
        "############################\n",
        "def clear_punctuation(s):\n",
        "    '''\n",
        "    This function removes all the punctuation from a sentence and insert a blank between any letter and !?.\n",
        "    :param s: a string\n",
        "    :return: the \"cleaned\" string\n",
        "    '''\n",
        "    # Remove all the character that are not letters, puntuation or numbers\n",
        "    s = re.sub(r\"[^a-zA-Z.!?,']+\", r\" \", s)\n",
        "    # Insert a blank between any letter and !?. using regex\n",
        "    #s = re.sub(r\"([a-zA-Z])([!?.])\", r\"\\1 \\2\", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "def pickle_dump(obj, PATH, name):\n",
        "    '''\n",
        "    Save an object to a pickle file\n",
        "    :param obj: object to save\n",
        "    :param path: path to the pickle file\n",
        "    '''\n",
        "    if not os.path.exists(PATH):\n",
        "        os.makedirs(PATH)\n",
        "\n",
        "    with open(PATH+name, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def pickle_load(PATH):\n",
        "    '''\n",
        "    Load an object from a pickle file\n",
        "    :param path: path to the pickle file\n",
        "    :return: the loaded object\n",
        "    '''\n",
        "    with open(PATH, 'rb') as f:\n",
        "        obj = pickle.load(f)\n",
        "    return obj\n",
        "\n",
        "def print_random_elements(collection, k=5):\n",
        "    '''\n",
        "    Print k random elements from a collection\n",
        "    :param collection: list of elements\n",
        "    :param k: number of elements to print\n",
        "    '''\n",
        "    random_elements = random.sample(collection, k=k)\n",
        "    for e in random_elements:\n",
        "        print(e)\n",
        "\n",
        "def collate_fn(batch,pad_idx):\n",
        "  data, targets = zip(*batch)\n",
        "  padded_data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=pad_idx)\n",
        "  padded_targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=pad_idx)\n",
        "  return padded_data, padded_targets\n",
        "\n",
        "def checkpoint(model,optimizer,path='./MyFiles/',save_name=None):\n",
        "  dic = {\n",
        "      'model_state' : model.state_dict(),\n",
        "      'optimizer' : optimizer.state_dict()\n",
        "  }\n",
        "  if save_name is not None:\n",
        "    torch.save(dic, path+save_name+\".pt\")\n",
        "  return dic\n",
        "\n",
        "def load_checkpoint(path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model_state = checkpoint['model_state']\n",
        "    optimizer_state = checkpoint['optimizer']\n",
        "    return model_state,optimizer_state\n",
        "\n",
        "def check_content_txt_files(convo_path, lines_path, num_elements):\n",
        "    '''\n",
        "    Check the content of the files\n",
        "    :param convo_path: path to the movie_conversations.txt file\n",
        "    :param lines_path: path to the movie_lines.txt file\n",
        "    :param num_elements: number of elements to print\n",
        "    '''\n",
        "    # Inspect movie_conversations.txt\n",
        "    with open(convo_path, 'r') as conv_file:\n",
        "        for i in range(num_elements):\n",
        "            line = conv_file.readline()\n",
        "\n",
        "    # Inspect movie_lines.txt\n",
        "    with open(lines_path, 'r') as lines_file:\n",
        "        for i in range(num_elements):\n",
        "            line = lines_file.readline()\n",
        "\n",
        "def get_reference_pairs(convo_path):\n",
        "    '''\n",
        "    Get the reference pairs\n",
        "    :return: a list of pairs of references of sentences\n",
        "    '''\n",
        "    ref_pairs = []\n",
        "    with open(convo_path, 'r') as conv_file:\n",
        "        for line in conv_file:\n",
        "            conversation = line.strip().split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").split(\",\")\n",
        "            for i in range(len(conversation) - 1):\n",
        "                ref_pairs.append((conversation[i].strip(), conversation[i+1].strip()))\n",
        "    return ref_pairs\n",
        "    \n",
        "\n",
        "def normalize_sentences(path_lines):\n",
        "    lines_dict = {}\n",
        "    empty_lines = 0\n",
        "    with open(path_lines, 'r', encoding='cp1252') as lines_file:\n",
        "        for full_line in lines_file:\n",
        "            line_split = full_line.split(' +++$+++ ')\n",
        "            line = line_split[-1]\n",
        "            line, is_line = process_sentence(line)\n",
        "            if is_line == 0:\n",
        "                empty_lines += 1\n",
        "            else:\n",
        "                lines_dict.update({line_split[0] : line})\n",
        "    return lines_dict, empty_lines\n",
        "\n",
        "def process_sentence(line):\n",
        "    is_line = 0\n",
        "    line = line.replace('\\n','').replace(\"<u>\",\"\").replace(\"</u>\",\"\").lower()\n",
        "    line = re.sub('-+','',line)\n",
        "    line = re.sub(r\"[^a-zA-Z.!?,']+\", r\" \", line)\n",
        "    line = re.sub(r\"i'm\", \"i am\", line, flags=re.I)\n",
        "    line = re.sub(r\"it's\", \"it is\", line, flags=re.I)\n",
        "    line = re.sub(r\"he's\", \"he is\", line, flags=re.I)\n",
        "    line = re.sub(r\"she's\", \"she is\", line, flags=re.I)\n",
        "    line = re.sub(r\"can't\", \"can not\", line, flags=re.I)\n",
        "    line = re.sub(r\"that's\", \"that is\", line, flags=re.I)\n",
        "    line = re.sub(r\"there's\", \"there is\", line, flags=re.I)\n",
        "    line = re.sub(r\"what's\", \"what is\", line, flags=re.I)\n",
        "    line = re.sub(r\"where's\", \"where is\", line, flags=re.I)\n",
        "    line = re.sub(r\"how's\", \"how is\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'ll\", \" will\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'s\", \" is\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'ve\", \" have\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'re\", \" are\", line, flags=re.I)\n",
        "    line = re.sub(r\"\\'d\", \" would\", line, flags=re.I)\n",
        "    line = re.sub(r\"n't\", \" not\", line, flags=re.I)\n",
        "    line = re.sub(r\"won't\", \"will not\", line, flags=re.I)\n",
        "    line = re.sub(r\"can't\", \"cannot\", line, flags=re.I)\n",
        "    line = line.strip()\n",
        "    if line == '' or line.isspace():\n",
        "        is_line += 1\n",
        "    else:\n",
        "        line = TreebankWordTokenizer().tokenize(line)\n",
        "    return line, is_line\n",
        "\n",
        "def get_valid_refs(ref_pairs, lines):\n",
        "    valid_refs = set()\n",
        "    for p in ref_pairs:\n",
        "        if p[0] in lines and p[1] in lines:\n",
        "            valid_refs.add(p[0])\n",
        "            valid_refs.add(p[1])\n",
        "    return valid_refs\n",
        "\n",
        "def generate_primitive_valid_pairs(all_ref_pairs, lines):\n",
        "    chosen_sentences = {}\n",
        "    chosen_ref_pairs = []\n",
        "\n",
        "    for p in all_ref_pairs:\n",
        "        if p[0] in lines and p[1] in lines:\n",
        "            chosen_sentences.update({p[0]: lines[p[0]]+['<EOS>']})\n",
        "            chosen_sentences.update({p[1]: ['<SOS>']+lines[p[1]]+['<EOS>']})  \n",
        "            chosen_ref_pairs.append(p)\n",
        "    return chosen_sentences, chosen_ref_pairs\n",
        "\n",
        "def eliminate_long_sentences(chosen_sentences, chosen_ref_pairs, max_length):\n",
        "    rule_out_sentences_refs = set()\n",
        "    chosen_sentences2 = {}\n",
        "    chosen_ref_pairs2 = []\n",
        "\n",
        "    for k,v in chosen_sentences.items():\n",
        "        if len(v) > max_length:\n",
        "            rule_out_sentences_refs.add(k)\n",
        "\n",
        "    for p in chosen_ref_pairs:\n",
        "        if p[0] not in rule_out_sentences_refs and p[1] not in rule_out_sentences_refs:\n",
        "            chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "            chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "            chosen_ref_pairs2.append(p)\n",
        "\n",
        "    return chosen_sentences2,chosen_ref_pairs2,rule_out_sentences_refs\n",
        "\n",
        "def eliminate_sentences_with_rare_words(chosen_sentences, chosen_ref_pairs, rule_out_words):\n",
        "    rule_out_sentences_refs = set()\n",
        "    chosen_sentences2 = {}\n",
        "    chosen_ref_pairs2 = []\n",
        "\n",
        "    for k,v in chosen_sentences.items():\n",
        "        if any(word in rule_out_words for word in v):\n",
        "            rule_out_sentences_refs.add(k)\n",
        "\n",
        "    for p in chosen_ref_pairs:\n",
        "        if p[0] not in rule_out_sentences_refs and p[1] not in rule_out_sentences_refs:\n",
        "            chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "            chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "            chosen_ref_pairs2.append(p)\n",
        "\n",
        "    return chosen_sentences2,chosen_ref_pairs2,rule_out_sentences_refs\n",
        "\n",
        "def count_words(chosen_ref_pairs, chosen_sentences):\n",
        "    word_counts = {}\n",
        "    for p in chosen_ref_pairs:\n",
        "        for r in p:\n",
        "            for w in chosen_sentences[r]:\n",
        "                if w in word_counts:\n",
        "                    word_counts[w] += 1\n",
        "                else:\n",
        "                    word_counts[w] = 1\n",
        "    num_words = sum(word_counts.values())\n",
        "    return word_counts, num_words\n",
        "\n",
        "\n",
        "def extract_sentences_from_refs(chosen_ref_pairs, chosen_sentences):\n",
        "    chosen_sentences2 = {}\n",
        "    for p in chosen_ref_pairs:\n",
        "        chosen_sentences2.update({p[0]: chosen_sentences[p[0]]})\n",
        "        chosen_sentences2.update({p[1]: chosen_sentences[p[1]]})\n",
        "    return chosen_sentences2 \n",
        "\n",
        "\n",
        "\n",
        "def prime_factors(n):\n",
        "    i = 2\n",
        "    while i * i <= n:\n",
        "        if n % i == 0:\n",
        "            n /= i\n",
        "            yield i\n",
        "        else:\n",
        "            i += 1\n",
        "    if n > 1:\n",
        "        yield n\n",
        "\n",
        "\n",
        "def prod(iterable):\n",
        "    result = 1\n",
        "    for i in iterable:\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_divisors(n):\n",
        "    pf = prime_factors(n)\n",
        "\n",
        "    pf_with_multiplicity = collections.Counter(pf)\n",
        "\n",
        "    powers = [\n",
        "        [factor ** i for i in range(count + 1)]\n",
        "        for factor, count in pf_with_multiplicity.items()\n",
        "    ]\n",
        "\n",
        "    for prime_power_combo in itertools.product(*powers):\n",
        "        yield prod(prime_power_combo)\n",
        "\n",
        "\n",
        "def create_pairs(path='./MyFiles/',savename=\"result\",max_length=26,word_frequency_discard=10,verbose=True):\n",
        "\n",
        "    if verbose:\n",
        "        check_content_txt_files('./Data/movie_conversations.txt', './Data/movie_lines.txt', 5)\n",
        "\n",
        "    all_ref_pairs = get_reference_pairs('./Data/movie_conversations.txt')\n",
        "\n",
        "    if verbose:\n",
        "        print_random_elements(all_ref_pairs)\n",
        "\n",
        "    lines,empty_lines = normalize_sentences('./Data/movie_lines.txt')\n",
        "\n",
        "    if verbose:\n",
        "        print('Number of empty lines: {}'.format(empty_lines))\n",
        "        print_random_elements(list(lines.values()))\n",
        "\n",
        "    chosen_sentences, chosen_ref_pairs = generate_primitive_valid_pairs(all_ref_pairs, lines)\n",
        "\n",
        "    if verbose:\n",
        "        print_random_elements(chosen_ref_pairs)\n",
        "\n",
        "        # Filter out the sentences that are too long\n",
        "        # Compute the length of each sentence\n",
        "        # Compute the mean and standard deviation for sentence lengths\n",
        "        sentence_lengths = []\n",
        "        for p in chosen_ref_pairs:\n",
        "            sentence_lengths.append(len(chosen_sentences[p[0]]))\n",
        "            sentence_lengths.append(len(chosen_sentences[p[1]]))\n",
        "\n",
        "        mean_length = statistics.mean(sentence_lengths)\n",
        "        std_dev = statistics.stdev(sentence_lengths)\n",
        "\n",
        "        print('Mean sentence length: {}'.format(mean_length))\n",
        "        print('Standard deviation: {}'.format(std_dev))\n",
        "        print('Max sentence length: {}'.format(max(sentence_lengths)))\n",
        "        print('Min sentence length: {}'.format(min(sentence_lengths)))\n",
        "\n",
        "        # Plot the histogram with logarithmic scale on the y-axis\n",
        "        plt.hist(sentence_lengths, density=True, bins=40)\n",
        "        plt.xlabel('Sentence Length')\n",
        "        plt.ylabel('Frequency (log scale)')\n",
        "        plt.title('Sentence Length Distribution')\n",
        "        plt.yscale('log')  # Set y-axis scale to logarithmic\n",
        "        plt.axvline(x=mean_length, color='r', linestyle='--', label='Mean')  # Add vertical line for the mean\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        # Compute the frequency of each sentence length\n",
        "        length_counts = {}\n",
        "        for length in sentence_lengths:\n",
        "            if length in length_counts:\n",
        "                length_counts[length] += 1\n",
        "            else:\n",
        "                length_counts[length] = 1\n",
        "\n",
        "        # Sort the sentence lengths in ascending order\n",
        "        sorted_lengths = sorted(length_counts.keys())\n",
        "\n",
        "        # Compute the accumulated frequency percentage\n",
        "        total_sentences = len(sentence_lengths)\n",
        "        accumulated_percentage = 0\n",
        "        percentage_values = []\n",
        "        for length in sorted_lengths:\n",
        "            frequency = length_counts[length]\n",
        "            percentage = (frequency / total_sentences) * 100\n",
        "            accumulated_percentage += percentage\n",
        "            percentage_values.append(accumulated_percentage)\n",
        "\n",
        "        # Plot the sentence lengths and their accumulated frequency percentage\n",
        "        plt.plot(sorted_lengths, percentage_values)\n",
        "        plt.xlabel('Sentence Length')\n",
        "        plt.ylabel('Accumulated Frequency Percentage')\n",
        "        plt.title('Sentence Length Distribution')\n",
        "        plt.show()\n",
        "\n",
        "    initial_num_sentences = len(chosen_sentences)\n",
        "    initial_num_pairs = len(chosen_ref_pairs)\n",
        "    chosen_sentences,chosen_ref_pairs,rule_out_sentences_refs = eliminate_long_sentences(chosen_sentences, chosen_ref_pairs, max_length) \n",
        "\n",
        "    if verbose:\n",
        "        print('Initial number of sentences: {}'.format(initial_num_sentences))\n",
        "        print('Current number of senteces: {}'.format(initial_num_sentences-len(rule_out_sentences_refs)))\n",
        "        print('Initial number of pairs: {}'.format(initial_num_pairs))\n",
        "        print('Current number of pairs: {}'.format(initial_num_pairs-len(chosen_ref_pairs)))\n",
        "\n",
        "\n",
        "    word_counts, num_words = count_words(chosen_ref_pairs, chosen_sentences)\n",
        "\n",
        "    if verbose:\n",
        "        print('Number of words: {}'.format(num_words))\n",
        "        print('Number of unique words: {}'.format(len(word_counts)))\n",
        "\n",
        "        plt.plot(range(len(word_counts)), list(word_counts.values()))\n",
        "        plt.xlabel('Word index')\n",
        "        plt.ylabel('Word frequency')\n",
        "        plt.suptitle('Word frequency distribution')\n",
        "        plt.title('Frequency per word')\n",
        "        plt.show()\n",
        "\n",
        "        # Compute the mean and standard deviation for word counts\n",
        "        mean_value = statistics.mean(word_counts.values())\n",
        "        print(\"Mean value:\", mean_value)\n",
        "        print(\"Max value:\", max(word_counts.values()))\n",
        "        print(\"Min value:\", min(word_counts.values()))\n",
        "\n",
        "        # Plot the distribution of word counts < mean\n",
        "        dict_lower_mean = {k: v for k, v in word_counts.items() if v < mean_value}\n",
        "        sorted_dict_lower_mean = dict(sorted(dict_lower_mean.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        plt.plot(range(len(sorted_dict_lower_mean)), sorted_dict_lower_mean.values())\n",
        "        plt.xlabel('Word index')\n",
        "        plt.ylabel('Word count')\n",
        "        plt.suptitle('Word count distribution')\n",
        "        plt.title('Words with count < mean')\n",
        "        plt.show()\n",
        "\n",
        "    # Frequency threshold and filter out the words that are too rare\n",
        "    rule_out_words = [k for k, v in word_counts.items() if v < word_frequency_discard]\n",
        "    chosen_sentences,chosen_ref_pairs,rule_out_sentences_refs = eliminate_sentences_with_rare_words(chosen_sentences, chosen_ref_pairs, rule_out_words)\n",
        "\n",
        "    if verbose:\n",
        "        print('Current number of senteces: {} ({:.2f}% of total)'.format(initial_num_sentences-len(chosen_sentences),(initial_num_sentences-len(chosen_sentences))/initial_num_sentences*100))\n",
        "        print('Current number of pairs: {} ({:.2f}% of total)'.format(initial_num_pairs-len(chosen_ref_pairs),(initial_num_pairs-len(chosen_ref_pairs))/initial_num_pairs*100))\n",
        "\n",
        "    # Save the pairs to a pickle file\n",
        "\n",
        "\n",
        "    pickle_dump(chosen_sentences,path,savename+\"_sentences.pkl\")\n",
        "    pickle_dump(chosen_ref_pairs,path,savename+\"_ref_pairs.pkl\")\n",
        "\n",
        "    return chosen_sentences,chosen_ref_pairs\n",
        "\n",
        "\n",
        "def train(epochs,model,optimizer,criterion,train_loader,val_loader,stopper,device,lr_scheduler,eval_period,clip=1.0):\n",
        "    train_losses, val_losses = [],[]\n",
        "    vocab = train_loader.dataset.vocabulary\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for i, (data, targets) in enumerate(train_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data,targets[:,:-1])\n",
        "            loss = criterion(output.view(-1,output.size(-1)),targets[:,1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            if clip:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "            optimizer.step()\n",
        "            if (i+1)%eval_period==0 or i==len(train_loader)-1:\n",
        "                train_losses.append(loss.item())\n",
        "\n",
        "                r_index = random.randint(0, len(data) - 1)\n",
        "                r_target = targets[r_index].view(-1).cpu().detach().numpy()\n",
        "                r_output = output[r_index].argmax(dim=-1).view(-1).cpu().detach().numpy()\n",
        "\n",
        "                # Evaluation\n",
        "                val_losses.append(evaluate(model, criterion, val_loader, device))\n",
        "                print(\"Epoch: {}/{}, Batch: {}/{}:\\n- Train Loss: {:.4f}\".format(epoch+1,epochs,i,len(train_loader),train_losses[-1]))\n",
        "                print(\"- Validation Loss: {:.4f}\\n\".format(val_losses[-1]))\n",
        "                print(\"- Target: \"+\" \".join([vocab.index2word[i] for i in r_target]))\n",
        "                print(\"- Output: \"+\" \".join([vocab.index2word[i] for i in r_output]))\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        if  stopper.check_early_stop(val_losses[-1], model):\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "    return train_losses, val_losses, model, stopper\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in val_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output = model(data, targets[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.size(-1)), targets[:, 1:].contiguous().view(-1))\n",
        "            val_loss += loss.item()\n",
        "    model.train()\n",
        "    return val_loss / len(val_loader)\n",
        "\n",
        "\n",
        "\n",
        "def train_ga(epochs, model, optimizer, criterion, train_loader, val_loader, stopper, device, lr_scheduler, print_every_n, accumulation_steps, vocab, clip=1.0):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        steps = 0\n",
        "\n",
        "        for i, (data, targets) in enumerate(train_loader):\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(data, targets[:, :-1])\n",
        "            loss = criterion(output.view(-1, output.size(-1)), targets[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                if clip:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                total_loss += loss.item()\n",
        "                steps += 1\n",
        "\n",
        "                if (i + 1) % print_every_n == 0:\n",
        "                    avg_loss = total_loss / steps\n",
        "                    train_losses.append(avg_loss)\n",
        "                    total_loss = 0.0\n",
        "                    steps = 0\n",
        "                    val_losses.append(evaluate(model, criterion, val_loader, device))\n",
        "\n",
        "                    r_index = random.randint(0, len(data) - 1)\n",
        "                    r_target = targets[r_index].view(-1).cpu().detach().numpy()\n",
        "                    r_output = output[r_index].argmax(dim=-1).view(-1).cpu().detach().numpy()\n",
        "                    print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}]\\n- Train Loss: {avg_loss:.4f}\")\n",
        "                    print(f\"- Validation Loss: {val_losses[-1]:.4f}\")\n",
        "                    print(\"- Target: \"+\" \".join([vocab.index2word[i] for i in r_target if i!=0]))\n",
        "                    print(\"- Output: \"+\" \".join([vocab.index2word[i] for i in r_output])+\"\\n\")\n",
        "                    \n",
        "\n",
        "\n",
        "\n",
        "        if  stopper.check_early_stop(val_losses[-1], model):\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses, model, stopper\n",
        "\n",
        "\n",
        "\n",
        "def inference(model, test_sentence, vocab, device, greedy=True):\n",
        "\n",
        "    line,_ = process_sentence(test_sentence)\n",
        "    line = line + ['<EOS>']\n",
        "    line = torch.tensor([vocab.word2index[word] for word in line]).unsqueeze(0)\n",
        "    target = torch.tensor([vocab.word2index[\"<SOS>\"]]).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        line,target= line.to(device), target.to(device)\n",
        "        for _ in range(20):\n",
        "            output = model(line,target)\n",
        "            if greedy:\n",
        "                next_word_idx = output.argmax(dim=-1)[:,-1].unsqueeze(1)\n",
        "            else:\n",
        "                next_word_idx = torch.multinomial(F.softmax(output,dim=-1)[:,-1],1)\n",
        "            target = torch.cat((target, next_word_idx), dim=1)\n",
        "            if next_word_idx.item() == vocab.word2index[\"<EOS>\"]:\n",
        "                break\n",
        "  \n",
        "        line = line.view(-1).detach().cpu().numpy()\n",
        "        target = target.view(-1).detach().cpu().numpy()\n",
        "        print(\"Input:\")\n",
        "        [print(vocab.index2word[i.item()],end=\" \") for i in line]\n",
        "        print(\"\\nOutput:\")\n",
        "        [print(vocab.index2word[i.item()],end=\" \") for i in target]\n",
        "\n",
        "def train_ga_hf(epochs, model, optimizer, criterion, train_loader, val_loader, device, lr_scheduler, accumulation_steps):\n",
        "    accelerator = Accelerator(gradient_accumulation_steps=accumulation_steps)\n",
        "    model, optimizer, train_loader, lr_scheduler = accelerator.prepare(model, optimizer, train_loader, lr_scheduler)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        for i, (data, targets) in enumerate(train_loader):\n",
        "            with accelerator.accumulate(model):\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                output = model(data, targets[:, :-1])\n",
        "                loss = criterion(output.view(-1, output.size(-1)), targets[:, 1:].contiguous().view(-1))\n",
        "                train_losses.append(loss.item())\n",
        "                accelerator.backward(loss)\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Print training progress\n",
        "                if i+1 % 100 == 0 or i == len(train_loader)-1:\n",
        "                    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "                    val_losses.append(val_loss)\n",
        "                    print(\"Epoch: {}/{}, Batch: {}/{}:\\n- Train Loss: {:.4f}\".format(epoch + 1, epochs, i+1, len(train_loader), train_losses[-1]))\n",
        "                    print(\"- Validation Loss: {:.4f}\\n\".format(val_loss))\n",
        "\n",
        "    return train_losses, val_losses, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Cyq1djiEBhE"
      },
      "outputs": [],
      "source": [
        "# Load pairs\n",
        "############################\n",
        "PATH = './MyFiles/'\n",
        "#chosen_sentences,chosen_ref_pairs = create_pairs(path='./MyFiles/',savename=\"result\",max_length=26,word_frequency_discard=10,verbose=True)\n",
        "chosen_sentences = pickle_load(PATH+'result_sentences.pkl')\n",
        "chosen_ref_pairs = pickle_load(PATH+'result_ref_pairs.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dump QA \n",
        "############################\n",
        "PATH = './MyFiles/'\n",
        "with open(PATH+'qa_dump.txt', 'w') as qa_dump:\n",
        "    for p in chosen_ref_pairs:\n",
        "        q = \" \".join(chosen_sentences[p[0]])\n",
        "        a = \" \".join(chosen_sentences[p[1]])\n",
        "        qa_dump.write(\"Q: \"+q+\"\\nA: \"+a+\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vuT53XoGEBhE"
      },
      "outputs": [],
      "source": [
        "# Pipeline parameters\n",
        "############################\n",
        "\n",
        "# Hyperparameters\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "batch_size = 256\n",
        "accumulation_steps = 4\n",
        "rand_sample_num = 40960\n",
        "learning_rate = 1e-3\n",
        "d_model = 768\n",
        "encoder_layers = 6\n",
        "decoder_layers = 6\n",
        "feed_forward_dim = 2048\n",
        "nheads = 8\n",
        "dropout_transformer = 0.2\n",
        "dropout_posenconding = 0\n",
        "patience = 3\n",
        "epochs = 2\n",
        "weight_decay = 0\n",
        "\n",
        "\n",
        "\n",
        "# Randomly sample pairs and splits\n",
        "rand_sample_num = min(rand_sample_num,len(chosen_ref_pairs))\n",
        "chosen_ref_pairs = random.sample(chosen_ref_pairs,rand_sample_num)\n",
        "grad_size = batch_size*accumulation_steps\n",
        "train_size = (int(0.8 * rand_sample_num)//grad_size)*grad_size\n",
        "val_size = (rand_sample_num-train_size)//2\n",
        "test_size = rand_sample_num-train_size-val_size\n",
        "train_pairs, test_pairs, val_pairs = random_split(chosen_ref_pairs,[train_size,val_size,test_size])\n",
        "\n",
        "# Vocabulary, Dataset and Dataloader\n",
        "vocab = Vocabulary(\"English\",chosen_sentences.values())\n",
        "train_dataset = Dataset(vocab,train_pairs,extract_sentences_from_refs(train_pairs, chosen_sentences))\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))\n",
        "val_dataset = Dataset(vocab,val_pairs,extract_sentences_from_refs(val_pairs, chosen_sentences))\n",
        "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3okvUcaCEBhE",
        "outputId": "f3d603f2-a9ac-4267-ce7c-33214103e3e8"
      },
      "outputs": [],
      "source": [
        "# Pipeline initialization\n",
        "############################\n",
        "\n",
        "# Model, criterion, optimizer and scheduler\n",
        "model = TransformerModel(vocab_size=len(vocab.word2index),d_model=d_model,pad_id=vocab.word2index[\"<PAD>\"],\n",
        "                         encoder_layers=encoder_layers,decoder_layers=decoder_layers,dim_feedforward=feed_forward_dim,\n",
        "                         num_heads=nheads,dropout_transformer=dropout_transformer, dropout_posenconding=dropout_posenconding).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95, verbose=False)\n",
        "stopper = EarlyStopper(patience=patience)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iRgZi-crEBhE",
        "outputId": "230dba3c-e23e-4cd6-d93e-0b2ab33bafe6"
      },
      "outputs": [],
      "source": [
        "# Standard Training\n",
        "############################\n",
        "eval_period = 8\n",
        "train_losses, val_losses, model, stopper = train(epochs,model,optimizer,criterion,train_loader,val_loader,stopper,device,lr_scheduler,eval_period,clip=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FDI_sH8rEBhF",
        "outputId": "5ad337c0-c5af-4bf5-8b9a-8a9e8d74f54a"
      },
      "outputs": [],
      "source": [
        "# Plot train losses and validation losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYykDUCmEBhF"
      },
      "outputs": [],
      "source": [
        "# Checkpointing\n",
        "############################\n",
        "\n",
        "PATH = './MyFiles/'\n",
        "#save_checkpoint = checkpoint(model,optimizer,path=PATH,save_name=\"checkpoint_dicts\")\n",
        "#torch.save(model, PATH+'model.pt')\n",
        "#model_state, optimizer_state = load_checkpoint(PATH+\"checkpoint_dicts.pt\")\n",
        "#pickle_dump(train_losses,PATH,\"train_losses.pkl\")\n",
        "#pickle_dump(val_losses,PATH,\"val_losses.pkl\")\n",
        "\n",
        "model = torch.load(PATH+'model.pt')\n",
        "train_losses = pickle_load(PATH+\"train_losses.pkl\")\n",
        "val_losses = pickle_load(PATH+\"val_losses.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test loss\n",
        "############################\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "\n",
        "testing_loader = DataLoader(Dataset(vocab,test_pairs,extract_sentences_from_refs(test_pairs,chosen_sentences)),batch_size=batch_size,\n",
        "                            shuffle=True,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, targets in testing_loader:\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        output = model(data, targets[:, :-1])\n",
        "        loss = criterion(output.view(-1, output.size(-1)), targets[:, 1:].contiguous().view(-1))\n",
        "        test_loss += loss.item()\n",
        "\n",
        "test_loss /= len(testing_loader)\n",
        "print(\"Test Loss: {:.4f}\".format(test_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            "no , mother. yes , mother. no , mother . <EOS> \n",
            "Output:\n",
            "<SOS> <EOS> "
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "############################\n",
        "testing_loader = DataLoader(Dataset(vocab,test_pairs,extract_sentences_from_refs(test_pairs,chosen_sentences)),batch_size=1,\n",
        "                            shuffle=True,collate_fn=lambda batch: collate_fn(batch,vocab.word2index[\"<PAD>\"]))\n",
        "data,_= next(iter(testing_loader))\n",
        "data = \" \".join([vocab.index2word[i] for i in data[0].detach().tolist()[:-1]])\n",
        "inference(model, data, vocab, device, greedy=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of batches: 128.0\n",
            "Size of batches: 256\n",
            "Update every 4 batches\n",
            "Number of possible logs per epoch: 32.0\n",
            "Divisors of 32.0: [1, 2, 4, 8, 16, 32]\n",
            "Frequency per epoch: [32.0, 16.0, 8.0, 4.0, 2.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# Auxiliary calculations\n",
        "############################\n",
        "\n",
        "def prime_factors(n):\n",
        "    i = 2\n",
        "    while i * i <= n:\n",
        "        if n % i == 0:\n",
        "            n /= i\n",
        "            yield i\n",
        "        else:\n",
        "            i += 1\n",
        "    if n > 1:\n",
        "        yield n\n",
        "\n",
        "\n",
        "def prod(iterable):\n",
        "    result = 1\n",
        "    for i in iterable:\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_divisors(n):\n",
        "    pf = prime_factors(n)\n",
        "\n",
        "    pf_with_multiplicity = collections.Counter(pf)\n",
        "\n",
        "    powers = [\n",
        "        [factor ** i for i in range(count + 1)]\n",
        "        for factor, count in pf_with_multiplicity.items()\n",
        "    ]\n",
        "\n",
        "    for prime_power_combo in itertools.product(*powers):\n",
        "        yield prod(prime_power_combo)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of batches: {}\".format(train_size/batch_size))\n",
        "print(\"Size of batches: {}\".format(batch_size))\n",
        "print(\"Update every {} batches\".format(accumulation_steps))\n",
        "possible_logs_per_epoch = train_size/(batch_size*accumulation_steps)\n",
        "print(\"Number of possible logs per epoch: {}\".format(possible_logs_per_epoch))\n",
        "divisors = list(get_divisors(possible_logs_per_epoch))\n",
        "print(\"Divisors of {}: {}\".format(possible_logs_per_epoch,divisors))\n",
        "print(\"Frequency per epoch: {}\".format((possible_logs_per_epoch/np.array(divisors)).tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fabiangobet/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/nn/modules/transformer.py:344: UserWarning: The operator 'aten::_nested_tensor_from_mask_left_aligned' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
            "  and not torch._nested_tensor_from_mask_left_aligned(src, src_key_padding_mask.logical_not())):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [16/128]\n",
            "- Train Loss: 7.8597\n",
            "- Validation Loss: 5.9586\n",
            "- Target: amen to that . <EOS>\n",
            "- Output: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m logs_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      4\u001b[0m print_every_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;66;03m#int(possible_logs_per_epoch/logs_per_epoch)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_losses, val_losses, model, stopper \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprint_every_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[3], line 451\u001b[0m, in \u001b[0;36mtrain_ga\u001b[0;34m(epochs, model, optimizer, criterion, train_loader, val_loader, stopper, device, lr_scheduler, print_every_n, accumulation_steps, vocab, clip)\u001b[0m\n\u001b[1;32m    449\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data, targets[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    450\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 451\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Gradient accumulation\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Gradient accumulation training\n",
        "############################\n",
        "logs_per_epoch = 16\n",
        "print_every_n = 16 #int(possible_logs_per_epoch/logs_per_epoch)\n",
        "\n",
        "train_losses, val_losses, model, stopper = train_ga(epochs,model,optimizer,criterion,train_loader,val_loader,stopper,device,lr_scheduler,print_every_n,accumulation_steps,vocab,clip=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fabiangobet/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/nn/modules/transformer.py:344: UserWarning: The operator 'aten::_nested_tensor_from_mask_left_aligned' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
            "  and not torch._nested_tensor_from_mask_left_aligned(src, src_key_padding_mask.logical_not())):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [4/128]\n",
            "- Train Loss: 6.2920\n",
            "- Validation Loss: 8.1519\n",
            "- Target: \n",
            "['thanks', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<PAD>', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "Epoch [1/1], Step [8/128]\n",
            "- Train Loss: 8.0723\n",
            "- Validation Loss: 6.4637\n",
            "- Target: \n",
            "['and', 'did', 'you', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you']\n",
            "Epoch [1/1], Step [12/128]\n",
            "- Train Loss: 6.4405\n",
            "- Validation Loss: 6.2107\n",
            "- Target: \n",
            "['what', 'do', 'you', 'mean', '?', 'you', 'have', 'been', 'frank', \"'s\", 'bird', 'ever', 'since', 'her', 'mother', 'cleared', 'off.', 'you', 'are', 'closer', 'to', 'her', 'than', 'anyone', '.', '<EOS>']\n",
            "- Output: \n",
            "['?', '?', '?', '?', '?', '?', '?', '.', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?', '?']\n",
            "Epoch [1/1], Step [16/128]\n",
            "- Train Loss: 6.0818\n",
            "- Validation Loss: 5.7922\n",
            "- Target: \n",
            "['right', ',', 'right', '...', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [20/128]\n",
            "- Train Loss: 5.8155\n",
            "- Validation Loss: 5.6676\n",
            "- Target: \n",
            "['<SOS>', 'just', 'over', 'a', 'year', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "Epoch [1/1], Step [24/128]\n",
            "- Train Loss: 5.6022\n",
            "- Validation Loss: 5.6324\n",
            "- Target: \n",
            "['<SOS>', 'it', 'is', 'not', 'really', 'a', 'good', 'time', ',', 'guys', '...', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "[',', '<EOS>', ',', '<EOS>', 'i', ',', ',', ',', ',', ',', '<EOS>', ',', ',', ',', ',', ',', ',', ',', '<EOS>', '<EOS>', 'i', ',', ',', ',', ',']\n",
            "Epoch [1/1], Step [28/128]\n",
            "- Train Loss: 5.6062\n",
            "- Validation Loss: 5.6372\n",
            "- Target: \n",
            "['<SOS>', 'it', 'is', 'dudley', 'for', 'the', 'nite', 'owl', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [32/128]\n",
            "- Train Loss: 5.5701\n",
            "- Validation Loss: 5.6239\n",
            "- Target: \n",
            "['that', 'is', 'under', 'lock', 'and', 'key', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [36/128]\n",
            "- Train Loss: 5.4439\n",
            "- Validation Loss: 5.6275\n",
            "- Target: \n",
            "['you', 'holding', 'up', 'alright', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '.', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [40/128]\n",
            "- Train Loss: 5.6215\n",
            "- Validation Loss: 5.6144\n",
            "- Target: \n",
            "['<SOS>', 'goodbye', ',', 'david', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '.', '.', '.', '.', '.', '<EOS>', '.', '<EOS>', '<EOS>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '<EOS>', '<EOS>', '<EOS>', '.', '.']\n",
            "Epoch [1/1], Step [44/128]\n",
            "- Train Loss: 5.5930\n",
            "- Validation Loss: 5.5897\n",
            "- Target: \n",
            "['i', 'will', 'take', 'it', 'from', 'here', 'i', 'am', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['.', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '.', '<EOS>', '.', '<EOS>', '<EOS>', '.', '<EOS>', '.', '.', '.', '<EOS>', '<EOS>', '<EOS>', '.', '<EOS>', '.', '.', '.', '.']\n",
            "Epoch [1/1], Step [48/128]\n",
            "- Train Loss: 5.4286\n",
            "- Validation Loss: 5.5681\n",
            "- Target: \n",
            "['<SOS>', 'then', 'someone', 'forged', 'a', 'data', 'bank', 'entry', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '.', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [52/128]\n",
            "- Train Loss: 5.4779\n",
            "- Validation Loss: 5.5493\n",
            "- Target: \n",
            "['rooney', \"'s\", 'protecting', 'someone.', 'who', 'is', 'she', 'protecting', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [56/128]\n",
            "- Train Loss: 5.5784\n",
            "- Validation Loss: 5.5323\n",
            "- Target: \n",
            "['<SOS>', 'well', ',', 'i', 'think', 'he', 'was', 'dying', 'to', 'open', 'up.', 'it', 'is', 'so', 'sad.', 'now', '...', 'what', 'should', 'i', 'wear', 'to', 'my', 'audition', '?', '<EOS>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
            "Epoch [1/1], Step [60/128]\n",
            "- Train Loss: 5.4743\n",
            "- Validation Loss: 5.5236\n",
            "- Target: \n",
            "['you', 'do', 'not', 'believe', 'that', 'either', ',', 'do', 'you', '?', 'why', 'can', 'not', 'you', 'see', 'my', 'side', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "- Output: \n",
            "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m logs_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      4\u001b[0m print_every_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(possible_logs_per_epoch\u001b[38;5;241m/\u001b[39mlogs_per_epoch)\n\u001b[0;32m----> 6\u001b[0m train_losses2, val_losses2, model, stopper \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprint_every_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[3], line 462\u001b[0m, in \u001b[0;36mtrain_ga\u001b[0;34m(epochs, model, optimizer, criterion, train_loader, val_loader, stopper, device, lr_scheduler, print_every_n, accumulation_steps, vocab, clip)\u001b[0m\n\u001b[1;32m    460\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data, targets[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    461\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 462\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# Gradient accumulation\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/pythonProject/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Gradient accumulation training\n",
        "############################\n",
        "logs_per_epoch = 16\n",
        "print_every_n = int(possible_logs_per_epoch/logs_per_epoch)\n",
        "\n",
        "train_losses2, val_losses2, model, stopper = train_ga(1,model,optimizer,criterion,train_loader,val_loader,stopper,device,lr_scheduler,print_every_n,accumulation_steps,vocab,clip=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot train losses and validation losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpointing\n",
        "############################\n",
        "\n",
        "PATH = './MyFiles/'\n",
        "#save_checkpoint = checkpoint(model,optimizer,path=PATH,save_name=\"checkpoint_dicts\")\n",
        "#torch.save(model, PATH+'model.pt')\n",
        "#model_state, optimizer_state = load_checkpoint(PATH+\"checkpoint_dicts.pt\")\n",
        "\n",
        "#pickle_dump(train_losses,PATH,\"train_losses.pkl\")\n",
        "#pickle_dump(val_losses,PATH,\"val_losses.pkl\")\n",
        "\n",
        "model = torch.load(PATH+'model.pt')\n",
        "#train_losses = pickle_load(PATH+\"train_losses.pkl\")\n",
        "#val_losses = pickle_load(PATH+\"val_losses.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_state_dict(model_state)\n",
        "optimizer.load_state_dict(optimizer_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradient accumulation hugging face training\n",
        "############################\n",
        "train_losses, val_losses, model = train_ga_hf(epochs, model, optimizer, criterion, train_loader, val_loader, device, lr_scheduler, accumulation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zurtE4HXEBhF"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # !!! Don't change the seed !!!\n",
        "    torch.manual_seed(42)\n",
        "    # !!!!!!\n",
        "\n",
        "    # Download the data\n",
        "\n",
        "    # SAVE and put the code above into a function that you will call if you need to generate something slightly different\n",
        "    PATH = './MyFiles/'\n",
        "    #pairs = create_pairs(path=PATH,savename1=\"pre_pairs\",savename2=\"pairs\",max_length=26,word_frequency_discard=10,verbose=False)\n",
        "    pairs = pickle_load(PATH+'pairs.pkl')\n",
        "\n",
        "    # Training loop (Consider writing a function for this/two separate functions for training and validation)\n",
        "\n",
        "    # Evaluation by feeding the model with one input sentence at a time\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
