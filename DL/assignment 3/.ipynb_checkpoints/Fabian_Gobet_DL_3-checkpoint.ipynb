{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generation of news titles using LSTM\n",
    "Data taken from: https://www.kaggle.com/datasets/rmisra/news-category-dataset/\n",
    "Student: NAME SURNAME\n",
    "'''\n",
    "# Packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc67bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_TBBTT(max_epochs, model, dataloader, criterion, optimizer, chunk_size, device, clip=None):\n",
    "    losses = []\n",
    "    perplexities = []\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs:\n",
    "        epoch += 1\n",
    "        model.train()\n",
    "        for input, output in dataloader:\n",
    "            # Get the number of chunks\n",
    "            n_chunks = input.shape[1] // chunk_size\n",
    "\n",
    "            # Loop on chunks\n",
    "            for j in range(n_chunks):\n",
    "                # TODO what is missing here?\n",
    "                # Switch between the chunks\n",
    "                if j < n_chunks - 1:\n",
    "                    input_chunk = input[:, j * chunk_size:(j + 1) * chunk_size].to(device).to(torch.int64)\n",
    "                    output_chunk = output[:, j * chunk_size:(j + 1) * chunk_size].to(device).to(torch.int64)\n",
    "                else:\n",
    "                    input_chunk = input[:, j * chunk_size:].to(device).to(torch.int64)\n",
    "                    output_chunk = output[:, j * chunk_size:].to(device).to(torch.int64)\n",
    "                # Initialise model's state and perform forward pass\n",
    "                # If it is the first chunk, initialise the state to 0\n",
    "                if j == 0:\n",
    "                    h, c = # TODO ?\n",
    "                else:  # Initialize the state to the previous state - detached!\n",
    "                    h, c = # TODO ?\n",
    "\n",
    "                # Forward step\n",
    "                # TODO: complete the forward step\n",
    "\n",
    "                # Calculate loss\n",
    "                # TODO complete the loss calculation\n",
    "\n",
    "                # Calculate gradients and update parameters\n",
    "                # TODO: complete the backward step\n",
    "                # Clipping if needed\n",
    "                # TODO: complete the clipping step\n",
    "                # Update parameters\n",
    "                # TODO: complete the update step\n",
    "\n",
    "        # Print loss and perplexity every epoch\n",
    "        # TODO: complete the perplexity calculation and loss / perpl priting\n",
    "\n",
    "        # TODO keep track of losses and perplexities\n",
    "        losses.append(0)\n",
    "        perplexities.append(0) # <--- Replace here\n",
    "\n",
    "        model.eval()\n",
    "        # TODO prompt a sentence from the model\n",
    "\n",
    "    return model, losses, perplexities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Do the exercise here!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
